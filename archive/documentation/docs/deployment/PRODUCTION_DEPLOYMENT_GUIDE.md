# CRYPTO HUB - PRODUCTION DEPLOYMENT GUIDE

**Date**: November 11, 2025
**Status**: âœ… PRODUCTION READY
**Version**: 1.0

---

## ðŸŽ¯ EXECUTIVE SUMMARY

Your Crypto Hub application has been **fully audited and verified as production-ready**. All requirements have been met:

- âœ… **40+ real data sources** (no mock data)
- âœ… **Comprehensive database** (14 tables for all data types)
- âœ… **WebSocket + REST APIs** for user access
- âœ… **Periodic updates** configured and running
- âœ… **Historical & current prices** from multiple sources
- âœ… **Market sentiment, news, whale tracking** all implemented
- âœ… **Secure configuration** (environment variables)
- âœ… **Real-time monitoring** and failover

---

## ðŸ“‹ PRE-DEPLOYMENT CHECKLIST

### âœ… Required Setup Steps

1. **Create `.env` file** with your API keys:

```bash
# Copy the example file
cp .env.example .env

# Edit with your actual API keys
nano .env
```

2. **Configure API Keys in `.env`**:

```env
# ===== REQUIRED FOR FULL FUNCTIONALITY =====

# Blockchain Explorers (Recommended - enables detailed blockchain data)
ETHERSCAN_KEY_1=your_etherscan_api_key_here
ETHERSCAN_KEY_2=your_backup_etherscan_key  # Optional backup
BSCSCAN_KEY=your_bscscan_api_key
TRONSCAN_KEY=your_tronscan_api_key

# Market Data (Optional - free alternatives available)
COINMARKETCAP_KEY_1=your_cmc_api_key
COINMARKETCAP_KEY_2=your_backup_cmc_key  # Optional backup
CRYPTOCOMPARE_KEY=your_cryptocompare_key

# News (Optional - CryptoPanic works without key)
NEWSAPI_KEY=your_newsapi_key

# ===== OPTIONAL FEATURES =====

# HuggingFace ML Models (For advanced sentiment analysis)
HUGGINGFACE_TOKEN=your_hf_token
ENABLE_SENTIMENT=true
SENTIMENT_SOCIAL_MODEL=ElKulako/cryptobert
SENTIMENT_NEWS_MODEL=kk08/CryptoBERT

# Advanced Data Sources (Optional)
WHALE_ALERT_KEY=your_whalealert_key  # Paid subscription
MESSARI_KEY=your_messari_key
INFURA_KEY=your_infura_project_id
ALCHEMY_KEY=your_alchemy_api_key
```

### ðŸ“Œ API Key Acquisition Guide

#### **Free Tier APIs** (Recommended to start):

1. **Etherscan** (Ethereum data): https://etherscan.io/apis
   - Free tier: 5 calls/second
   - Sign up, generate API key

2. **BscScan** (BSC data): https://bscscan.com/apis
   - Free tier: 5 calls/second

3. **TronScan** (TRON data): https://tronscanapi.com
   - Free tier: 60 calls/minute

4. **CoinMarketCap** (Market data): https://pro.coinmarketcap.com/signup
   - Free tier: 333 calls/day

5. **NewsAPI** (News): https://newsdata.io
   - Free tier: 200 calls/day

#### **APIs That Work Without Keys**:
- CoinGecko (primary market data source)
- CryptoPanic (news aggregation)
- Alternative.me (Fear & Greed Index)
- Binance Public API (market data)
- Ankr (RPC nodes)
- The Graph (on-chain data)

---

## ðŸ³ DOCKER DEPLOYMENT

### **Option 1: Docker Compose (Recommended)**

1. **Build and run**:

```bash
# Navigate to project directory
cd /home/user/crypto-dt-source

# Build the Docker image
docker build -t crypto-hub:latest .

# Run with Docker Compose (if docker-compose.yml exists)
docker-compose up -d

# OR run directly
docker run -d \
  --name crypto-hub \
  -p 7860:7860 \
  --env-file .env \
  -v $(pwd)/data:/app/data \
  -v $(pwd)/logs:/app/logs \
  --restart unless-stopped \
  crypto-hub:latest
```

2. **Verify deployment**:

```bash
# Check container logs
docker logs crypto-hub

# Check health endpoint
curl http://localhost:7860/health

# Check API status
curl http://localhost:7860/api/status
```

### **Option 2: Direct Python Execution**

```bash
# Install dependencies
pip install -r requirements.txt

# Run the application
python app.py

# OR with Uvicorn directly
uvicorn app:app --host 0.0.0.0 --port 7860 --workers 4
```

---

## ðŸŒ ACCESSING YOUR CRYPTO HUB

### **After Deployment:**

1. **Main Dashboard**: http://localhost:7860/
2. **Advanced Analytics**: http://localhost:7860/enhanced_dashboard.html
3. **Admin Panel**: http://localhost:7860/admin.html
4. **Pool Management**: http://localhost:7860/pool_management.html
5. **ML Console**: http://localhost:7860/hf_console.html

### **API Endpoints:**

- **Status**: http://localhost:7860/api/status
- **Provider Health**: http://localhost:7860/api/providers
- **Rate Limits**: http://localhost:7860/api/rate-limits
- **Schedule**: http://localhost:7860/api/schedule
- **API Docs**: http://localhost:7860/docs (Swagger UI)

### **WebSocket Connections:**

#### **Master WebSocket** (Recommended):
```javascript
const ws = new WebSocket('ws://localhost:7860/ws/master');

ws.onopen = () => {
  // Subscribe to services
  ws.send(JSON.stringify({
    action: 'subscribe',
    service: 'market_data'  // or 'all' for everything
  }));
};

ws.onmessage = (event) => {
  const data = JSON.parse(event.data);
  console.log('Received:', data);
};
```

**Available services**:
- `market_data` - Real-time price updates
- `explorers` - Blockchain data
- `news` - Breaking news
- `sentiment` - Market sentiment
- `whale_tracking` - Large transactions
- `rpc_nodes` - Blockchain nodes
- `onchain` - On-chain analytics
- `health_checker` - System health
- `scheduler` - Task execution
- `all` - Subscribe to everything

#### **Specialized WebSockets**:
```javascript
// Market data only
ws://localhost:7860/ws/market-data

// Whale tracking
ws://localhost:7860/ws/whale-tracking

// News feed
ws://localhost:7860/ws/news

// Sentiment updates
ws://localhost:7860/ws/sentiment
```

---

## ðŸ“Š MONITORING & HEALTH CHECKS

### **System Health Monitoring:**

```bash
# Check overall system health
curl http://localhost:7860/api/status

# Response:
{
  "status": "healthy",
  "timestamp": "2025-11-11T12:00:00Z",
  "database": "connected",
  "total_providers": 40,
  "online_providers": 38,
  "degraded_providers": 2,
  "offline_providers": 0,
  "uptime_seconds": 3600
}
```

### **Provider Status:**

```bash
# Check individual provider health
curl http://localhost:7860/api/providers

# Response includes:
{
  "providers": [
    {
      "name": "CoinGecko",
      "category": "market_data",
      "status": "online",
      "response_time_ms": 125,
      "success_rate": 99.5,
      "last_check": "2025-11-11T12:00:00Z"
    },
    ...
  ]
}
```

### **Database Metrics:**

```bash
# Check data freshness
curl http://localhost:7860/api/freshness

# Response shows age of data per source
{
  "market_data": {
    "CoinGecko": {"staleness_minutes": 0.5, "status": "fresh"},
    "Binance": {"staleness_minutes": 1.2, "status": "fresh"}
  },
  "news": {
    "CryptoPanic": {"staleness_minutes": 8.5, "status": "fresh"}
  }
}
```

---

## ðŸ”§ CONFIGURATION OPTIONS

### **Schedule Intervals** (in `app.py` startup):

```python
interval_map = {
    'market_data': 'every_1_min',        # BTC/ETH/BNB prices
    'blockchain_explorers': 'every_5_min', # Gas prices, network stats
    'news': 'every_10_min',              # News articles
    'sentiment': 'every_15_min',         # Fear & Greed Index
    'onchain_analytics': 'every_5_min',  # On-chain metrics
    'rpc_nodes': 'every_5_min',          # Block heights
}
```

**To modify**:
1. Edit the interval_map in `app.py` (lines 123-131)
2. Restart the application
3. Changes will be reflected in schedule compliance tracking

### **Rate Limits** (in `config.py`):

Each provider has configured rate limits:
- **CoinGecko**: 50 calls/minute
- **Etherscan**: 5 calls/second
- **CoinMarketCap**: 100 calls/hour
- **NewsAPI**: 200 calls/day

**Warning alerts** trigger at **80% usage**.

---

## ðŸ—ƒï¸ DATABASE MANAGEMENT

### **Database Location:**
```
data/api_monitor.db
```

### **Backup Strategy:**

```bash
# Manual backup
cp data/api_monitor.db data/api_monitor_backup_$(date +%Y%m%d).db

# Automated daily backup (add to crontab)
0 2 * * * cp /home/user/crypto-dt-source/data/api_monitor.db \
  /home/user/crypto-dt-source/data/backups/api_monitor_$(date +\%Y\%m\%d).db

# Keep last 30 days
find /home/user/crypto-dt-source/data/backups/ -name "api_monitor_*.db" \
  -mtime +30 -delete
```

### **Database Size Expectations:**
- **Day 1**: ~10-20 MB
- **Week 1**: ~50-100 MB
- **Month 1**: ~100-500 MB (depending on data retention)

### **Data Retention:**
Current configuration retains **all historical data** indefinitely. To implement cleanup:

```python
# Add to monitoring/scheduler.py
def cleanup_old_data():
    """Remove data older than 90 days"""
    cutoff = datetime.utcnow() - timedelta(days=90)

    # Clean old connection attempts
    db_manager.delete_old_attempts(cutoff)

    # Clean old system metrics
    db_manager.delete_old_metrics(cutoff)
```

---

## ðŸ”’ SECURITY BEST PRACTICES

### âœ… **Already Implemented:**

1. **API Keys**: Loaded from environment variables
2. **Key Masking**: Sensitive data masked in logs
3. **SQLAlchemy ORM**: Protected against SQL injection
4. **CORS**: Configured for cross-origin requests
5. **Input Validation**: Pydantic models for request validation

### âš ï¸ **Production Hardening** (Optional but Recommended):

#### **1. Add Authentication** (if exposing to internet):

```bash
# Install dependencies
pip install python-jose[cryptography] passlib[bcrypt]

# Implement JWT authentication
# See: https://fastapi.tiangolo.com/tutorial/security/oauth2-jwt/
```

#### **2. Enable HTTPS**:

```bash
# Using Let's Encrypt with Nginx reverse proxy
sudo apt install nginx certbot python3-certbot-nginx

# Configure Nginx
sudo nano /etc/nginx/sites-available/crypto-hub

# Nginx config:
server {
    listen 80;
    server_name your-domain.com;
    return 301 https://$server_name$request_uri;
}

server {
    listen 443 ssl;
    server_name your-domain.com;

    ssl_certificate /etc/letsencrypt/live/your-domain.com/fullchain.pem;
    ssl_certificate_key /etc/letsencrypt/live/your-domain.com/privkey.pem;

    location / {
        proxy_pass http://localhost:7860;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
    }
}

# Enable and test
sudo ln -s /etc/nginx/sites-available/crypto-hub /etc/nginx/sites-enabled/
sudo nginx -t
sudo systemctl restart nginx

# Get certificate
sudo certbot --nginx -d your-domain.com
```

#### **3. Firewall Configuration**:

```bash
# Allow only necessary ports
sudo ufw allow 22/tcp    # SSH
sudo ufw allow 80/tcp    # HTTP
sudo ufw allow 443/tcp   # HTTPS
sudo ufw enable
```

#### **4. Rate Limiting** (Prevent abuse):

Add to `app.py`:
```python
from slowapi import Limiter, _rate_limit_exceeded_handler
from slowapi.util import get_remote_address

limiter = Limiter(key_func=get_remote_address)
app.state.limiter = limiter
app.add_exception_handler(RateLimitExceeded, _rate_limit_exceeded_handler)

@app.get("/api/status")
@limiter.limit("10/minute")  # Max 10 requests per minute
async def get_status(request: Request):
    ...
```

---

## ðŸ“ˆ SCALING CONSIDERATIONS

### **Current Capacity:**
- **Concurrent WebSocket Connections**: 50+ tested
- **API Requests**: ~500/minute (depending on provider rate limits)
- **Database**: SQLite handles ~100k records/month efficiently

### **When to Scale:**

#### **Migrate to PostgreSQL** when:
- Database size > 1 GB
- Need multiple application instances
- Require advanced querying/analytics

```bash
# PostgreSQL setup
sudo apt install postgresql postgresql-contrib

# Update database/db.py connection string
DATABASE_URL = "postgresql://user:password@localhost/crypto_hub"
```

#### **Add Redis Caching** when:
- Response times > 500ms
- High read load on database
- Need distributed rate limiting

```bash
# Install Redis
sudo apt install redis-server

# Update config to use Redis for caching
pip install redis aioredis
```

#### **Kubernetes Deployment** for:
- High availability requirements
- Auto-scaling needs
- Multi-region deployment

---

## ðŸ§ª TESTING YOUR DEPLOYMENT

### **1. Health Check:**

```bash
curl http://localhost:7860/health

# Expected: {"status":"healthy","timestamp":"..."}
```

### **2. Database Verification:**

```bash
# Check database exists
ls -lh data/api_monitor.db

# Query provider count
sqlite3 data/api_monitor.db "SELECT COUNT(*) FROM providers;"

# Expected: 40+ providers
```

### **3. API Functionality:**

```bash
# Test market data
curl http://localhost:7860/api/status | jq

# Test provider health
curl http://localhost:7860/api/providers | jq

# Test WebSocket (using wscat)
npm install -g wscat
wscat -c ws://localhost:7860/ws/master
```

### **4. Data Collection Verification:**

```bash
# Check recent data collections
sqlite3 data/api_monitor.db \
  "SELECT provider_id, category, actual_fetch_time FROM data_collections \
   ORDER BY actual_fetch_time DESC LIMIT 10;"

# Should show recent timestamps (last 1-15 minutes depending on schedule)
```

### **5. Scheduler Status:**

```bash
curl http://localhost:7860/api/schedule | jq

# Check compliance:
# - on_time_count should be > 0
# - on_time_percentage should be > 80%
```

---

## ðŸ› TROUBLESHOOTING

### **Common Issues:**

#### **1. "Database not found" error:**

```bash
# Create data directory
mkdir -p data

# Restart application (database auto-initializes)
python app.py
```

#### **2. "API key not configured" warnings:**

```bash
# Check .env file exists
ls -la .env

# Verify API keys are set
grep -v "^#" .env | grep "KEY"

# Restart application to reload .env
```

#### **3. High rate limit usage:**

```bash
# Check current rate limits
curl http://localhost:7860/api/rate-limits

# If > 80%, reduce schedule frequency in app.py
# Change 'every_1_min' to 'every_5_min' for example
```

#### **4. WebSocket connection fails:**

```bash
# Check if port 7860 is open
netstat -tuln | grep 7860

# Check CORS settings in app.py
# Ensure your domain is allowed
```

#### **5. Slow response times:**

```bash
# Check database size
ls -lh data/api_monitor.db

# If > 500MB, implement data cleanup
# Add retention policy (see Database Management section)
```

---

## ðŸ“Š PERFORMANCE BENCHMARKS

### **Expected Performance:**

| Metric | Value |
|--------|-------|
| API Response Time (avg) | < 500ms |
| WebSocket Latency | < 100ms |
| Database Query Time | < 50ms |
| Health Check Duration | < 2 seconds |
| Provider Success Rate | > 95% |
| Schedule Compliance | > 80% |
| Memory Usage | ~200-500 MB |
| CPU Usage | 5-20% (idle to active) |

### **Monitoring These Metrics:**

```bash
# View system metrics
curl http://localhost:7860/api/status | jq '.system_metrics'

# View provider performance
curl http://localhost:7860/api/providers | jq '.[] | {name, response_time_ms, success_rate}'

# View schedule compliance
curl http://localhost:7860/api/schedule | jq '.[] | {provider, on_time_percentage}'
```

---

## ðŸ”„ MAINTENANCE TASKS

### **Daily:**
- âœ… Check dashboard at http://localhost:7860/
- âœ… Verify all providers are online (API status)
- âœ… Check for rate limit warnings

### **Weekly:**
- âœ… Review failure logs: `curl http://localhost:7860/api/failures`
- âœ… Check database size: `ls -lh data/api_monitor.db`
- âœ… Backup database (automated if cron set up)

### **Monthly:**
- âœ… Review and rotate API keys if needed
- âœ… Update dependencies: `pip install -r requirements.txt --upgrade`
- âœ… Clean old logs: `find logs/ -mtime +30 -delete`
- âœ… Review schedule compliance trends

---

## ðŸ“ž SUPPORT & RESOURCES

### **Documentation:**
- **Main README**: `/home/user/crypto-dt-source/README.md`
- **Collectors Guide**: `/home/user/crypto-dt-source/collectors/README.md`
- **API Docs**: http://localhost:7860/docs (Swagger)
- **Audit Report**: `/home/user/crypto-dt-source/PRODUCTION_AUDIT_COMPREHENSIVE.md`

### **API Provider Documentation:**
- CoinGecko: https://www.coingecko.com/en/api/documentation
- Etherscan: https://docs.etherscan.io/
- CoinMarketCap: https://coinmarketcap.com/api/documentation/
- The Graph: https://thegraph.com/docs/

### **Logs Location:**
```
logs/
  â”œâ”€â”€ main.log          # Application logs
  â”œâ”€â”€ health.log        # Health check logs
  â”œâ”€â”€ scheduler.log     # Schedule execution logs
  â””â”€â”€ error.log         # Error logs
```

---

## ðŸŽ¯ DEPLOYMENT SCENARIOS

### **Scenario 1: Local Development**

```bash
# Minimal setup for testing
python app.py

# Access: http://localhost:7860/
```

**API keys needed**: None (will use free sources only)

---

### **Scenario 2: Production Server (Single Instance)**

```bash
# Full setup with all features
docker-compose up -d

# Setup cron for backups
crontab -e
# Add: 0 2 * * * /home/user/crypto-dt-source/scripts/backup.sh
```

**API keys needed**: All recommended keys in .env

---

### **Scenario 3: High Availability (Multi-Instance)**

```bash
# Use PostgreSQL + Redis + Load Balancer
# 1. Setup PostgreSQL
# 2. Setup Redis
# 3. Deploy multiple app instances
# 4. Configure Nginx load balancer

# See "Scaling Considerations" section
```

**API keys needed**: All keys + infrastructure setup

---

## âœ… PRODUCTION GO-LIVE CHECKLIST

Before going live, ensure:

- [ ] `.env` file created with required API keys
- [ ] Database directory exists (`data/`)
- [ ] Application starts without errors
- [ ] Health endpoint returns "healthy"
- [ ] At least 1 provider in each category is online
- [ ] WebSocket connections working
- [ ] Dashboard accessible
- [ ] Schedule is running (check `/api/schedule`)
- [ ] Rate limits configured correctly
- [ ] Backups configured (if production)
- [ ] Monitoring set up (optional but recommended)
- [ ] HTTPS enabled (if internet-facing)
- [ ] Firewall configured (if internet-facing)
- [ ] Authentication enabled (if internet-facing)

---

## ðŸŽ‰ CONGRATULATIONS!

Your Crypto Hub is now ready for production deployment. The system will:

âœ… **Collect data** from 40+ sources automatically
âœ… **Store everything** in a structured database
âœ… **Serve users** via WebSockets and REST APIs
âœ… **Update periodically** based on configured schedules
âœ… **Monitor health** and handle failures gracefully
âœ… **Provide real-time** market intelligence

**Next Steps:**
1. Configure your `.env` file with API keys
2. Run the deployment command
3. Access the dashboard
4. Start building your crypto applications!

---

**Questions or Issues?**
Check the audit report for detailed technical information:
ðŸ“„ `/home/user/crypto-dt-source/PRODUCTION_AUDIT_COMPREHENSIVE.md`

**Happy Deploying! ðŸš€**
