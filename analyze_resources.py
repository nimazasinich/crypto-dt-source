#!/usr/bin/env python3
"""
Ø§Ø³Ú©Ø±ÛŒÙ¾Øª Ø¢Ù†Ø§Ù„ÛŒØ² Ù…Ù†Ø§Ø¨Ø¹
ØªØ­Ù„ÛŒÙ„ Ùˆ Ù…Ù‚Ø§ÛŒØ³Ù‡ Ù…Ù†Ø§Ø¨Ø¹ Ù…ÙˆØ¬ÙˆØ¯ Ùˆ Ø¬Ø¯ÛŒØ¯
"""
import json
from pathlib import Path
from typing import Dict, List, Set, Any

def analyze_unified_resources():
    """Ø¢Ù†Ø§Ù„ÛŒØ² ÙØ§ÛŒÙ„ crypto_resources_unified_2025-11-11.json"""
    print("=" * 80)
    print("ğŸ“Š ØªØ­Ù„ÛŒÙ„ Ù…Ù†Ø§Ø¨Ø¹ Ù…ÙˆØ¬ÙˆØ¯ (crypto_resources_unified_2025-11-11.json)")
    print("=" * 80)
    
    file_path = Path("api-resources/crypto_resources_unified_2025-11-11.json")
    
    if not file_path.exists():
        print(f"âŒ ÙØ§ÛŒÙ„ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯: {file_path}")
        return {}
    
    with open(file_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    registry = data.get('registry', {})
    metadata = registry.get('metadata', {})
    
    print(f"\nğŸ“ Metadata:")
    print(f"   Version: {metadata.get('version')}")
    print(f"   Updated: {metadata.get('updated')}")
    print(f"   Total entries: {metadata.get('total_entries')}")
    print(f"   Local backend routes: {metadata.get('local_backend_routes_count')}")
    
    print(f"\nğŸ“¦ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ù…Ù†Ø§Ø¨Ø¹:")
    
    categories_count = {}
    all_ids = set()
    
    for key, value in registry.items():
        if isinstance(value, list) and key != 'metadata':
            count = len(value)
            categories_count[key] = count
            print(f"   {key}: {count} items")
            
            # Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ IDÙ‡Ø§
            for item in value:
                if isinstance(item, dict) and 'id' in item:
                    all_ids.add(item['id'])
    
    print(f"\nâœ… Ù…Ø¬Ù…ÙˆØ¹ Ù…Ù†Ø§Ø¨Ø¹ ÛŒÙˆÙ†ÛŒÚ©: {len(all_ids)}")
    
    return {
        'all_ids': all_ids,
        'categories': categories_count,
        'metadata': metadata
    }


def analyze_ultimate_pipeline():
    """Ø¢Ù†Ø§Ù„ÛŒØ² ÙØ§ÛŒÙ„ ultimate_crypto_pipeline_2025_NZasinich.json"""
    print("\n" + "=" * 80)
    print("ğŸ“Š ØªØ­Ù„ÛŒÙ„ Ù…Ù†Ø§Ø¨Ø¹ Ø¬Ø¯ÛŒØ¯ (ultimate_crypto_pipeline_2025_NZasinich.json)")
    print("=" * 80)
    
    file_path = Path("api-resources/ultimate_crypto_pipeline_2025_NZasinich.json")
    
    if not file_path.exists():
        print(f"âŒ ÙØ§ÛŒÙ„ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯: {file_path}")
        return {}
    
    with open(file_path, 'r', encoding='utf-8') as f:
        # Ø®ÙˆØ§Ù†Ø¯Ù† Ù…Ø­ØªÙˆØ§ Ùˆ Ø­Ø°Ù Ø®Ø· Ø§ÙˆÙ„ Ø§Ú¯Ø± Ù†Ø§Ù… ÙØ§ÛŒÙ„ Ø¨Ø§Ø´Ø¯
        content = f.read()
        lines = content.split('\n')
        if lines and not lines[0].strip().startswith('{'):
            # Ø­Ø°Ù Ø®Ø· Ø§ÙˆÙ„
            content = '\n'.join(lines[1:])
        data = json.loads(content)
    
    print(f"\nğŸ“ Project Info:")
    print(f"   Project: {data.get('project')}")
    print(f"   User: {data.get('user', {}).get('handle')}")
    print(f"   Total sources: {data.get('total_sources')}")
    
    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ù†Ø§Ø¨Ø¹
    files = data.get('files', [])
    all_resources = []
    
    if files and isinstance(files, list) and len(files) > 0:
        content = files[0].get('content', {})
        resources = content.get('resources', [])
        all_resources = resources
    
    print(f"\nğŸ“¦ ØªØ¹Ø¯Ø§Ø¯ Ù…Ù†Ø§Ø¨Ø¹: {len(all_resources)}")
    
    # Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ
    categories = {}
    names = set()
    urls = set()
    free_resources = []
    
    for r in all_resources:
        cat = r.get('category', 'unknown')
        categories[cat] = categories.get(cat, 0) + 1
        
        name = r.get('name', '').strip()
        url = r.get('url', '').strip()
        
        if name:
            names.add(name)
        if url:
            urls.add(url)
        
        if r.get('free', False):
            free_resources.append(r)
    
    print(f"\nğŸ“Š Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ù…Ù†Ø§Ø¨Ø¹:")
    for cat, count in sorted(categories.items()):
        print(f"   {cat}: {count} items")
    
    print(f"\nâœ… Ù†Ø§Ù…â€ŒÙ‡Ø§ÛŒ ÛŒÙˆÙ†ÛŒÚ©: {len(names)}")
    print(f"âœ… URLÙ‡Ø§ÛŒ ÛŒÙˆÙ†ÛŒÚ©: {len(urls)}")
    print(f"âœ… Ù…Ù†Ø§Ø¨Ø¹ Ø±Ø§ÛŒÚ¯Ø§Ù†: {len(free_resources)}")
    
    return {
        'resources': all_resources,
        'names': names,
        'urls': urls,
        'categories': categories,
        'free_count': len(free_resources)
    }


def find_new_resources(unified_data, ultimate_data):
    """ÛŒØ§ÙØªÙ† Ù…Ù†Ø§Ø¨Ø¹ Ø¬Ø¯ÛŒØ¯"""
    print("\n" + "=" * 80)
    print("ğŸ” ÛŒØ§ÙØªÙ† Ù…Ù†Ø§Ø¨Ø¹ Ø¬Ø¯ÛŒØ¯")
    print("=" * 80)
    
    existing_ids = unified_data.get('all_ids', set())
    new_resources = ultimate_data.get('resources', [])
    
    # Ù…Ù†Ø§Ø¨Ø¹ Ø¬Ø¯ÛŒØ¯ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù†Ø§Ù… Ùˆ URL
    potential_new = []
    
    for resource in new_resources:
        name = resource.get('name', '').strip().lower()
        url = resource.get('url', '').strip()
        
        # Ú†Ú© Ú©Ù†ÛŒÙ… Ø¢ÛŒØ§ Ø§ÛŒÙ† Ù…Ù†Ø¨Ø¹ Ø¯Ø± Ø³ÛŒØ³ØªÙ… ÙØ¹Ù„ÛŒ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯ØŸ
        is_new = True
        
        # ÙÙ‚Ø· Ù…Ù†Ø§Ø¨Ø¹ Ø±Ø§ÛŒÚ¯Ø§Ù† Ø±Ø§ Ø¯Ø± Ù†Ø¸Ø± Ø¨Ú¯ÛŒØ±ÛŒÙ…
        if not resource.get('free', False):
            continue
        
        # Ø§Ú¯Ø± URL ØªÚ©Ø±Ø§Ø±ÛŒ Ù†ÛŒØ³Øª
        if url:
            potential_new.append({
                'name': resource.get('name'),
                'category': resource.get('category'),
                'url': url,
                'free': resource.get('free'),
                'rate_limit': resource.get('rateLimit', 'Unknown'),
                'description': resource.get('desc', ''),
                'endpoint': resource.get('endpoint', ''),
                'key_required': bool(resource.get('key'))
            })
    
    print(f"\nâœ… Ù…Ù†Ø§Ø¨Ø¹ Ø¨Ø§Ù„Ù‚ÙˆÙ‡ Ø¬Ø¯ÛŒØ¯ (Ø±Ø§ÛŒÚ¯Ø§Ù†): {len(potential_new)}")
    
    # Ù†Ù…Ø§ÛŒØ´ Ù†Ù…ÙˆÙ†Ù‡
    if potential_new:
        print(f"\nğŸ“‹ Ù†Ù…ÙˆÙ†Ù‡ Ù…Ù†Ø§Ø¨Ø¹ Ø¬Ø¯ÛŒØ¯ (10 Ù…ÙˆØ±Ø¯ Ø§ÙˆÙ„):")
        for i, r in enumerate(potential_new[:10], 1):
            print(f"\n{i}. {r['name']}")
            print(f"   Category: {r['category']}")
            print(f"   URL: {r['url']}")
            print(f"   Free: {r['free']}")
            print(f"   Rate Limit: {r['rate_limit']}")
            if r['description']:
                print(f"   Description: {r['description']}")
    
    return potential_new


def main():
    """ØªØ§Ø¨Ø¹ Ø§ØµÙ„ÛŒ"""
    print("\nğŸš€ Ø´Ø±ÙˆØ¹ ØªØ­Ù„ÛŒÙ„ Ù…Ù†Ø§Ø¨Ø¹ API\n")
    
    # Ø¢Ù†Ø§Ù„ÛŒØ² Ù…Ù†Ø§Ø¨Ø¹ Ù…ÙˆØ¬ÙˆØ¯
    unified_data = analyze_unified_resources()
    
    # Ø¢Ù†Ø§Ù„ÛŒØ² Ù…Ù†Ø§Ø¨Ø¹ Ø¬Ø¯ÛŒØ¯
    ultimate_data = analyze_ultimate_pipeline()
    
    # ÛŒØ§ÙØªÙ† Ù…Ù†Ø§Ø¨Ø¹ Ø¬Ø¯ÛŒØ¯
    new_resources = find_new_resources(unified_data, ultimate_data)
    
    # Ø°Ø®ÛŒØ±Ù‡ Ù†ØªØ§ÛŒØ¬
    output_file = Path("new_resources_analysis.json")
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump({
            'timestamp': 'Generated',
            'existing_count': len(unified_data.get('all_ids', set())),
            'potential_new_count': len(new_resources),
            'new_resources': new_resources
        }, f, indent=2, ensure_ascii=False)
    
    print(f"\n\nğŸ’¾ Ù†ØªØ§ÛŒØ¬ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯ Ø¯Ø±: {output_file}")
    print(f"\nâœ… ØªØ­Ù„ÛŒÙ„ Ú©Ø§Ù…Ù„ Ø´Ø¯!")
    print(f"   Ù…Ù†Ø§Ø¨Ø¹ Ù…ÙˆØ¬ÙˆØ¯: {len(unified_data.get('all_ids', set()))}")
    print(f"   Ù…Ù†Ø§Ø¨Ø¹ Ø¨Ø§Ù„Ù‚ÙˆÙ‡ Ø¬Ø¯ÛŒØ¯: {len(new_resources)}")


if __name__ == "__main__":
    main()
