#!/usr/bin/env python3
"""
Crypto Intelligence Hub - Hugging Face Space Application
ÛŒÚ©Ù¾Ø§Ø±Ú†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ú©Ø§Ù…Ù„ Ø¨Ú©â€ŒØ§Ù†Ø¯ Ùˆ ÙØ±Ø§Ù†Øªâ€ŒØ§Ù†Ø¯ Ø¨Ø±Ø§ÛŒ Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø±Ù…Ø² Ø§Ø±Ø²
Hub Ú©Ø§Ù…Ù„ Ø¨Ø§ Ù…Ù†Ø§Ø¨Ø¹ Ø±Ø§ÛŒÚ¯Ø§Ù† Ùˆ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Hugging Face

Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ø§Ø² Ø¯Ùˆ Ø­Ø§Ù„Øª:
1. Gradio UI (Ù¾ÛŒØ´â€ŒÙØ±Ø¶)
2. FastAPI + HTML (Ø¯Ø± ØµÙˆØ±Øª ØªÙ†Ø¸ÛŒÙ… USE_FASTAPI_HTML=true)
"""

import os
import json
import asyncio
import logging
from pathlib import Path
from typing import Dict, List, Optional, Any
from datetime import datetime
import gradio as gr
import pandas as pd
import plotly.graph_objects as go
import plotly.express as px
import httpx

# Import backend services
try:
    from api_server_extended import app as fastapi_app
    from ai_models import ModelRegistry, MODEL_SPECS, get_model_info, registry_status

    FASTAPI_AVAILABLE = True
except ImportError as e:
    logging.warning(f"FastAPI not available: {e}")
    FASTAPI_AVAILABLE = False
    ModelRegistry = None
    MODEL_SPECS = {}
    get_model_info = None
    registry_status = None

# Setup logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Environment detection
IS_DOCKER = (
    os.path.exists("/.dockerenv")
    or os.path.exists("/app")
    or os.getenv("DOCKER_CONTAINER") == "true"
)
# Default to FastAPI+HTML in Docker, Gradio otherwise
USE_FASTAPI_HTML = os.getenv("USE_FASTAPI_HTML", "true" if IS_DOCKER else "false").lower() == "true"
USE_GRADIO = os.getenv("USE_GRADIO", "false" if IS_DOCKER else "true").lower() == "true"

# Global state
WORKSPACE_ROOT = Path("/app" if Path("/app").exists() else Path("."))
RESOURCES_JSON = WORKSPACE_ROOT / "api-resources" / "crypto_resources_unified_2025-11-11.json"
ALL_APIS_JSON = WORKSPACE_ROOT / "all_apis_merged_2025.json"

# Fallback paths
if not RESOURCES_JSON.exists():
    RESOURCES_JSON = WORKSPACE_ROOT / "all_apis_merged_2025.json"
if not ALL_APIS_JSON.exists():
    ALL_APIS_JSON = WORKSPACE_ROOT / "all_apis_merged_2025.json"

# Initialize model registry
model_registry = ModelRegistry() if ModelRegistry else None


class CryptoDataHub:
    """Ù…Ø±Ú©Ø² Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø±Ù…Ø² Ø§Ø±Ø² Ø¨Ø§ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ø§Ø² Ù…Ù†Ø§Ø¨Ø¹ Ø±Ø§ÛŒÚ¯Ø§Ù† Ùˆ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Hugging Face"""

    def __init__(self):
        self.resources = {}
        self.models_loaded = False
        self.load_resources()
        self.initialize_models()

    def load_resources(self):
        """Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ù†Ø§Ø¨Ø¹ Ø§Ø² ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ JSON"""
        try:
            # Load unified resources
            if RESOURCES_JSON.exists():
                with open(RESOURCES_JSON, "r", encoding="utf-8") as f:
                    data = json.load(f)
                    self.resources["unified"] = data
                    logger.info(f"âœ… Loaded unified resources: {RESOURCES_JSON}")

            # Load all APIs merged
            if ALL_APIS_JSON.exists():
                with open(ALL_APIS_JSON, "r", encoding="utf-8") as f:
                    data = json.load(f)
                    self.resources["all_apis"] = data
                    logger.info(f"âœ… Loaded all APIs: {ALL_APIS_JSON}")

            logger.info(f"ğŸ“Š Total resource files loaded: {len(self.resources)}")
        except Exception as e:
            logger.error(f"âŒ Error loading resources: {e}")

    def initialize_models(self):
        """Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Hugging Face"""
        if not model_registry:
            logger.warning("Model registry not available")
            return

        try:
            # Initialize available models
            result = model_registry.initialize_models()
            self.models_loaded = result.get("status") == "ok"
            logger.info(f"âœ… Hugging Face models initialized: {result}")
        except Exception as e:
            logger.warning(f"âš ï¸ Could not initialize all models: {e}")

    def get_market_data_sources(self) -> List[Dict]:
        """Ø¯Ø±ÛŒØ§ÙØª Ù…Ù†Ø§Ø¨Ø¹ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¨Ø§Ø²Ø§Ø±"""
        sources = []

        # Try unified resources first
        if "unified" in self.resources:
            registry = self.resources["unified"].get("registry", {})

            # Market data APIs
            market_apis = registry.get("market_data", [])
            for api in market_apis:
                sources.append(
                    {
                        "name": api.get("name", "Unknown"),
                        "category": "market",
                        "base_url": api.get("base_url", ""),
                        "free": api.get("free", False),
                        "auth_required": bool(api.get("auth", {}).get("key")),
                    }
                )

        # Try all_apis structure
        if "all_apis" in self.resources:
            data = self.resources["all_apis"]

            # Check for discovered_keys which indicates market data sources
            if "discovered_keys" in data:
                for provider, keys in data["discovered_keys"].items():
                    if provider in ["coinmarketcap", "cryptocompare"]:
                        sources.append(
                            {
                                "name": provider.upper(),
                                "category": "market",
                                "base_url": (
                                    f"https://api.{provider}.com"
                                    if provider == "coinmarketcap"
                                    else f"https://min-api.{provider}.com"
                                ),
                                "free": False,
                                "auth_required": True,
                            }
                        )

            # Check raw_files for API configurations
            if "raw_files" in data:
                for file_info in data["raw_files"]:
                    content = file_info.get("content", "")
                    if "CoinGecko" in content or "coingecko" in content.lower():
                        sources.append(
                            {
                                "name": "CoinGecko",
                                "category": "market",
                                "base_url": "https://api.coingecko.com/api/v3",
                                "free": True,
                                "auth_required": False,
                            }
                        )
                    if "Binance" in content or "binance" in content.lower():
                        sources.append(
                            {
                                "name": "Binance Public",
                                "category": "market",
                                "base_url": "https://api.binance.com/api/v3",
                                "free": True,
                                "auth_required": False,
                            }
                        )

        # Remove duplicates
        seen = set()
        unique_sources = []
        for source in sources:
            key = source["name"]
            if key not in seen:
                seen.add(key)
                unique_sources.append(source)

        return unique_sources

    def get_available_models(self) -> List[Dict]:
        """Ø¯Ø±ÛŒØ§ÙØª Ù„ÛŒØ³Øª Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø¯Ø± Ø¯Ø³ØªØ±Ø³"""
        models = []

        if MODEL_SPECS:
            for key, spec in MODEL_SPECS.items():
                models.append(
                    {
                        "key": key,
                        "name": spec.model_id,
                        "task": spec.task,
                        "category": spec.category,
                        "requires_auth": spec.requires_auth,
                    }
                )

        return models

    async def analyze_sentiment(
        self, text: str, model_key: str = "crypto_sent_0", use_backend: bool = False
    ) -> Dict:
        """ØªØ­Ù„ÛŒÙ„ Ø§Ø­Ø³Ø§Ø³Ø§Øª Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Hugging Face"""
        # Try backend API first if requested and available
        if use_backend and FASTAPI_AVAILABLE:
            try:
                async with httpx.AsyncClient(timeout=30.0) as client:
                    response = await client.post(
                        "http://localhost:7860/api/hf/run-sentiment",
                        json={"texts": [text]},
                        headers={"Content-Type": "application/json"},
                    )
                    if response.status_code == 200:
                        data = response.json()
                        if data.get("results"):
                            result = data["results"][0]
                            return {
                                "sentiment": result.get("label", "unknown"),
                                "confidence": result.get("confidence", 0.0),
                                "model": "backend_api",
                                "text": text[:100],
                                "vote": result.get("vote", 0.0),
                            }
            except Exception as e:
                logger.warning(f"Backend API call failed, falling back to direct model: {e}")

        # Direct model access
        if not model_registry or not self.models_loaded:
            return {"error": "Models not available", "sentiment": "unknown", "confidence": 0.0}

        try:
            pipeline = model_registry.get_pipeline(model_key)
            result = pipeline(text)

            # Handle different result formats
            if isinstance(result, list) and len(result) > 0:
                result = result[0]

            return {
                "sentiment": result.get("label", "unknown"),
                "confidence": result.get("score", 0.0),
                "model": model_key,
                "text": text[:100],
            }
        except Exception as e:
            logger.error(f"Error analyzing sentiment: {e}")
            return {"error": str(e), "sentiment": "error", "confidence": 0.0}

    def get_resource_summary(self) -> Dict:
        """Ø®Ù„Ø§ØµÙ‡ Ù…Ù†Ø§Ø¨Ø¹ Ù…ÙˆØ¬ÙˆØ¯"""
        summary = {
            "total_resources": 0,
            "categories": {},
            "free_resources": 0,
            "models_available": len(self.get_available_models()),
        }

        if "unified" in self.resources:
            registry = self.resources["unified"].get("registry", {})

            for category, items in registry.items():
                if isinstance(items, list):
                    count = len(items)
                    summary["total_resources"] += count
                    summary["categories"][category] = count

                    # Count free resources
                    free_count = sum(1 for item in items if item.get("free", False))
                    summary["free_resources"] += free_count

        # Add market sources
        market_sources = self.get_market_data_sources()
        if market_sources:
            summary["total_resources"] += len(market_sources)
            summary["categories"]["market_data"] = len(market_sources)
            summary["free_resources"] += sum(1 for s in market_sources if s.get("free", False))

        return summary


# Initialize global hub
hub = CryptoDataHub()


# =============================================================================
# Gradio Interface Functions
# =============================================================================


def get_dashboard_summary():
    """Ù†Ù…Ø§ÛŒØ´ Ø®Ù„Ø§ØµÙ‡ Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯"""
    summary = hub.get_resource_summary()

    html = f"""
    <div style="padding: 20px; font-family: Arial, sans-serif;">
        <h2>ğŸ“Š Ø®Ù„Ø§ØµÙ‡ Ù…Ù†Ø§Ø¨Ø¹ Ùˆ Ù…Ø¯Ù„â€ŒÙ‡Ø§</h2>
        
        <div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); gap: 20px; margin: 20px 0;">
            <div style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); padding: 20px; border-radius: 10px; color: white;">
                <h3>Ù…Ù†Ø§Ø¨Ø¹ Ú©Ù„</h3>
                <p style="font-size: 32px; margin: 10px 0; font-weight: bold;">{summary['total_resources']}</p>
            </div>
            
            <div style="background: linear-gradient(135deg, #11998e 0%, #38ef7d 100%); padding: 20px; border-radius: 10px; color: white;">
                <h3>Ù…Ù†Ø§Ø¨Ø¹ Ø±Ø§ÛŒÚ¯Ø§Ù†</h3>
                <p style="font-size: 32px; margin: 10px 0; font-weight: bold;">{summary['free_resources']}</p>
            </div>
            
            <div style="background: linear-gradient(135deg, #ee0979 0%, #ff6a00 100%); padding: 20px; border-radius: 10px; color: white;">
                <h3>Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ AI</h3>
                <p style="font-size: 32px; margin: 10px 0; font-weight: bold;">{summary['models_available']}</p>
            </div>
            
            <div style="background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%); padding: 20px; border-radius: 10px; color: white;">
                <h3>Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§</h3>
                <p style="font-size: 32px; margin: 10px 0; font-weight: bold;">{len(summary['categories'])}</p>
            </div>
        </div>
        
        <h3>Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ù…Ù†Ø§Ø¨Ø¹:</h3>
        <ul>
    """

    for category, count in summary["categories"].items():
        html += f"<li><strong>{category}:</strong> {count} Ù…Ù†Ø¨Ø¹</li>"

    html += """
        </ul>
    </div>
    """

    return html


def get_resources_table():
    """Ø¬Ø¯ÙˆÙ„ Ù…Ù†Ø§Ø¨Ø¹"""
    sources = hub.get_market_data_sources()

    if not sources:
        return pd.DataFrame({"Ù¾ÛŒØ§Ù…": ["Ù‡ÛŒÚ† Ù…Ù†Ø¨Ø¹ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯. Ù„Ø·ÙØ§Ù‹ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ JSON Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†ÛŒØ¯."]})

    df_data = []
    for source in sources[:100]:  # Limit to 100 for display
        df_data.append(
            {
                "Ù†Ø§Ù…": source["name"],
                "Ø¯Ø³ØªÙ‡": source["category"],
                "Ø±Ø§ÛŒÚ¯Ø§Ù†": "âœ…" if source["free"] else "âŒ",
                "Ù†ÛŒØ§Ø² Ø¨Ù‡ Ú©Ù„ÛŒØ¯": "âœ…" if source["auth_required"] else "âŒ",
                "URL Ù¾Ø§ÛŒÙ‡": (
                    source["base_url"][:60] + "..."
                    if len(source["base_url"]) > 60
                    else source["base_url"]
                ),
            }
        )

    return pd.DataFrame(df_data)


def get_models_table():
    """Ø¬Ø¯ÙˆÙ„ Ù…Ø¯Ù„â€ŒÙ‡Ø§"""
    models = hub.get_available_models()

    if not models:
        return pd.DataFrame({"Ù¾ÛŒØ§Ù…": ["Ù‡ÛŒÚ† Ù…Ø¯Ù„ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯. Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù‡Ø³ØªÙ†Ø¯..."]})

    df_data = []
    for model in models:
        df_data.append(
            {
                "Ú©Ù„ÛŒØ¯": model["key"],
                "Ù†Ø§Ù… Ù…Ø¯Ù„": model["name"],
                "Ù†ÙˆØ¹ Ú©Ø§Ø±": model["task"],
                "Ø¯Ø³ØªÙ‡": model["category"],
                "Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø§Ø­Ø±Ø§Ø² Ù‡ÙˆÛŒØª": "âœ…" if model["requires_auth"] else "âŒ",
            }
        )

    return pd.DataFrame(df_data)


def analyze_text_sentiment(text: str, model_selection: str, use_backend: bool = False):
    """ØªØ­Ù„ÛŒÙ„ Ø§Ø­Ø³Ø§Ø³Ø§Øª Ù…ØªÙ†"""
    if not text.strip():
        return "âš ï¸ Ù„Ø·ÙØ§Ù‹ Ù…ØªÙ†ÛŒ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯", ""

    try:
        # Extract model key from dropdown selection
        if model_selection and " - " in model_selection:
            model_key = model_selection.split(" - ")[0]
        else:
            model_key = model_selection if model_selection else "crypto_sent_0"

        result = asyncio.run(hub.analyze_sentiment(text, model_key, use_backend=use_backend))

        if "error" in result:
            return f"âŒ Ø®Ø·Ø§: {result['error']}", ""

        sentiment_emoji = {
            "POSITIVE": "ğŸ“ˆ",
            "NEGATIVE": "ğŸ“‰",
            "NEUTRAL": "â¡ï¸",
            "LABEL_0": "ğŸ“ˆ",
            "LABEL_1": "ğŸ“‰",
            "LABEL_2": "â¡ï¸",
            "positive": "ğŸ“ˆ",
            "negative": "ğŸ“‰",
            "neutral": "â¡ï¸",
            "bullish": "ğŸ“ˆ",
            "bearish": "ğŸ“‰",
        }.get(result["sentiment"], "â“")

        confidence_pct = (
            result["confidence"] * 100 if result["confidence"] <= 1.0 else result["confidence"]
        )

        vote_info = ""
        if "vote" in result:
            vote_emoji = "ğŸ“ˆ" if result["vote"] > 0 else "ğŸ“‰" if result["vote"] < 0 else "â¡ï¸"
            vote_info = f"\n**Ø±Ø£ÛŒ Ù…Ø¯Ù„:** {vote_emoji} {result['vote']:.2f}"

        result_text = f"""
## Ù†ØªÛŒØ¬Ù‡ ØªØ­Ù„ÛŒÙ„ Ø§Ø­Ø³Ø§Ø³Ø§Øª

**Ø§Ø­Ø³Ø§Ø³Ø§Øª:** {sentiment_emoji} {result['sentiment']}
**Ø§Ø¹ØªÙ…Ø§Ø¯:** {confidence_pct:.2f}%
**Ù…Ø¯Ù„ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø´Ø¯Ù‡:** {result['model']}
**Ù…ØªÙ† ØªØ­Ù„ÛŒÙ„ Ø´Ø¯Ù‡:** {result['text']}
{vote_info}
        """

        result_json = json.dumps(result, indent=2, ensure_ascii=False)

        return result_text, result_json
    except Exception as e:
        return f"âŒ Ø®Ø·Ø§ Ø¯Ø± ØªØ­Ù„ÛŒÙ„: {str(e)}", ""


def create_category_chart():
    """Ù†Ù…ÙˆØ¯Ø§Ø± Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ù…Ù†Ø§Ø¨Ø¹"""
    summary = hub.get_resource_summary()

    categories = list(summary["categories"].keys())
    counts = list(summary["categories"].values())

    if not categories:
        fig = go.Figure()
        fig.add_annotation(
            text="No data available", xref="paper", yref="paper", x=0.5, y=0.5, showarrow=False
        )
        return fig

    fig = go.Figure(
        data=[
            go.Bar(
                x=categories, y=counts, marker_color="lightblue", text=counts, textposition="auto"
            )
        ]
    )

    fig.update_layout(
        title="ØªÙˆØ²ÛŒØ¹ Ù…Ù†Ø§Ø¨Ø¹ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ",
        xaxis_title="Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ",
        yaxis_title="ØªØ¹Ø¯Ø§Ø¯ Ù…Ù†Ø§Ø¨Ø¹",
        template="plotly_white",
        height=400,
    )

    return fig


def get_model_status():
    """ÙˆØ¶Ø¹ÛŒØª Ù…Ø¯Ù„â€ŒÙ‡Ø§"""
    if not registry_status:
        return "âŒ Model registry not available"

    status = registry_status()

    html = f"""
    <div style="padding: 20px;">
        <h3>ÙˆØ¶Ø¹ÛŒØª Ù…Ø¯Ù„â€ŒÙ‡Ø§</h3>
        <p><strong>ÙˆØ¶Ø¹ÛŒØª:</strong> {'âœ… ÙØ¹Ø§Ù„' if status.get('ok') else 'âŒ ØºÛŒØ±ÙØ¹Ø§Ù„'}</p>
        <p><strong>Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯Ù‡:</strong> {status.get('pipelines_loaded', 0)}</p>
        <p><strong>Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø¯Ø± Ø¯Ø³ØªØ±Ø³:</strong> {len(status.get('available_models', []))}</p>
        <p><strong>Ø­Ø§Ù„Øª Hugging Face:</strong> {status.get('hf_mode', 'unknown')}</p>
        <p><strong>Transformers Ù…ÙˆØ¬ÙˆØ¯:</strong> {'âœ…' if status.get('transformers_available') else 'âŒ'}</p>
    </div>
    """

    return html


# =============================================================================
# Build Gradio Interface
# =============================================================================


def create_gradio_interface():
    """Ø§ÛŒØ¬Ø§Ø¯ Ø±Ø§Ø¨Ø· Ú©Ø§Ø±Ø¨Ø±ÛŒ Gradio"""

    # Get available models for dropdown
    models = hub.get_available_models()
    model_choices = (
        [f"{m['key']} - {m['name']}" for m in models] if models else ["crypto_sent_0 - CryptoBERT"]
    )
    model_keys = [m["key"] for m in models] if models else ["crypto_sent_0"]

    with gr.Blocks(
        theme=gr.themes.Soft(primary_hue="blue", secondary_hue="purple"),
        title="Crypto Intelligence Hub - Ù…Ø±Ú©Ø² Ù‡ÙˆØ´ Ø±Ù…Ø² Ø§Ø±Ø²",
        css="""
        .gradio-container {
            max-width: 1400px !important;
        }
        """,
    ) as app:

        gr.Markdown(
            """
        # ğŸš€ Crypto Intelligence Hub
        ## Ù…Ø±Ú©Ø² Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ùˆ Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø±Ù…Ø² Ø§Ø±Ø²
        
        **Ù…Ù†Ø§Ø¨Ø¹ Ø±Ø§ÛŒÚ¯Ø§Ù† | Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Hugging Face | Ø±Ø§Ø¨Ø· Ú©Ø§Ø±Ø¨Ø±ÛŒ Ú©Ø§Ù…Ù„**
        
        Ø§ÛŒÙ† Ø¨Ø±Ù†Ø§Ù…Ù‡ ÛŒÚ© Ø±Ø§Ø¨Ø· Ú©Ø§Ù…Ù„ Ø¨Ø±Ø§ÛŒ Ø¯Ø³ØªØ±Ø³ÛŒ Ø¨Ù‡ Ù…Ù†Ø§Ø¨Ø¹ Ø±Ø§ÛŒÚ¯Ø§Ù† Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø±Ù…Ø² Ø§Ø±Ø² Ùˆ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Hugging Face Ø§Ø³Øª.
        """
        )

        # Tab 1: Dashboard
        with gr.Tab("ğŸ“Š Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯"):
            dashboard_summary = gr.HTML()
            refresh_dashboard_btn = gr.Button("ğŸ”„ Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ", variant="primary")

            refresh_dashboard_btn.click(fn=get_dashboard_summary, outputs=dashboard_summary)

            app.load(fn=get_dashboard_summary, outputs=dashboard_summary)

        # Tab 2: Resources
        with gr.Tab("ğŸ“š Ù…Ù†Ø§Ø¨Ø¹ Ø¯Ø§Ø¯Ù‡"):
            gr.Markdown("### Ù…Ù†Ø§Ø¨Ø¹ Ø±Ø§ÛŒÚ¯Ø§Ù† Ø¨Ø±Ø§ÛŒ Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø±Ù…Ø² Ø§Ø±Ø²")

            resources_table = gr.DataFrame(label="Ù„ÛŒØ³Øª Ù…Ù†Ø§Ø¨Ø¹", wrap=True)

            refresh_resources_btn = gr.Button("ğŸ”„ Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ", variant="primary")

            refresh_resources_btn.click(fn=get_resources_table, outputs=resources_table)

            app.load(fn=get_resources_table, outputs=resources_table)

            category_chart = gr.Plot(label="Ù†Ù…ÙˆØ¯Ø§Ø± Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ")

            refresh_resources_btn.click(fn=create_category_chart, outputs=category_chart)

        # Tab 3: AI Models
        with gr.Tab("ğŸ¤– Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ AI"):
            gr.Markdown("### Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Hugging Face Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ø§Ø­Ø³Ø§Ø³Ø§Øª Ùˆ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ")

            model_status_html = gr.HTML()

            models_table = gr.DataFrame(label="Ù„ÛŒØ³Øª Ù…Ø¯Ù„â€ŒÙ‡Ø§", wrap=True)

            refresh_models_btn = gr.Button("ğŸ”„ Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ", variant="primary")

            refresh_models_btn.click(fn=get_models_table, outputs=models_table)

            refresh_models_btn.click(fn=get_model_status, outputs=model_status_html)

            app.load(fn=get_models_table, outputs=models_table)

            app.load(fn=get_model_status, outputs=model_status_html)

        # Tab 4: Sentiment Analysis
        with gr.Tab("ğŸ’­ ØªØ­Ù„ÛŒÙ„ Ø§Ø­Ø³Ø§Ø³Ø§Øª"):
            gr.Markdown("### ØªØ­Ù„ÛŒÙ„ Ø§Ø­Ø³Ø§Ø³Ø§Øª Ù…ØªÙ† Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Hugging Face")

            with gr.Row():
                sentiment_text = gr.Textbox(
                    label="Ù…ØªÙ† Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„",
                    placeholder="Ù…Ø«Ø§Ù„: Bitcoin price is rising rapidly! The market shows strong bullish momentum.",
                    lines=5,
                )

            with gr.Row():
                model_dropdown = gr.Dropdown(
                    choices=model_choices,
                    value=model_choices[0] if model_choices else None,
                    label="Ø§Ù†ØªØ®Ø§Ø¨ Ù…Ø¯Ù„",
                )
                use_backend_check = gr.Checkbox(
                    label="Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø¨Ú©â€ŒØ§Ù†Ø¯ API (Ø¯Ø± ØµÙˆØ±Øª Ù…ÙˆØ¬ÙˆØ¯ Ø¨ÙˆØ¯Ù†)", value=False
                )
                analyze_btn = gr.Button("ğŸ” ØªØ­Ù„ÛŒÙ„", variant="primary")

            with gr.Row():
                sentiment_result = gr.Markdown(label="Ù†ØªÛŒØ¬Ù‡")
                sentiment_json = gr.Code(label="JSON Ø®Ø±ÙˆØ¬ÛŒ", language="json")

            def analyze_with_selected_model(text, model_choice, use_backend):
                return analyze_text_sentiment(text, model_choice, use_backend=use_backend)

            analyze_btn.click(
                fn=analyze_with_selected_model,
                inputs=[sentiment_text, model_dropdown, use_backend_check],
                outputs=[sentiment_result, sentiment_json],
            )

            # Example texts
            gr.Markdown(
                """
            ### Ù…Ø«Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ù…ØªÙ†:
            - "Bitcoin is showing strong bullish momentum"
            - "Market crash expected due to regulatory concerns"
            - "Ethereum network upgrade successful"
            - "Crypto market sentiment is very positive today"
            """
            )

        # Tab 5: API Integration
        with gr.Tab("ğŸ”Œ ÛŒÚ©Ù¾Ø§Ø±Ú†Ù‡â€ŒØ³Ø§Ø²ÛŒ API"):
            gr.Markdown(
                """
            ### Ø§ØªØµØ§Ù„ Ø¨Ù‡ Ø¨Ú©â€ŒØ§Ù†Ø¯ FastAPI
            
            Ø§ÛŒÙ† Ø¨Ø®Ø´ Ø¨Ù‡ Ø³Ø±ÙˆÛŒØ³â€ŒÙ‡Ø§ÛŒ Ø¨Ú©â€ŒØ§Ù†Ø¯ Ù…ØªØµÙ„ Ù…ÛŒâ€ŒØ´ÙˆØ¯ Ú©Ù‡ Ø§Ø² Ù…Ù†Ø§Ø¨Ø¹ JSON Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ù†Ø¯.
            
            **ÙˆØ¶Ø¹ÛŒØª:** {'âœ… ÙØ¹Ø§Ù„' if FASTAPI_AVAILABLE else 'âŒ ØºÛŒØ±ÙØ¹Ø§Ù„'}
            """
            )

            if FASTAPI_AVAILABLE:
                gr.Markdown(
                    """
                **API Endpoints Ø¯Ø± Ø¯Ø³ØªØ±Ø³:**
                - `/api/market-data` - Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¨Ø§Ø²Ø§Ø±
                - `/api/sentiment` - ØªØ­Ù„ÛŒÙ„ Ø§Ø­Ø³Ø§Ø³Ø§Øª
                - `/api/news` - Ø§Ø®Ø¨Ø§Ø± Ø±Ù…Ø² Ø§Ø±Ø²
                - `/api/resources` - Ù„ÛŒØ³Øª Ù…Ù†Ø§Ø¨Ø¹
                """
                )

            # Show resource summary
            resource_info = gr.Markdown()

            def get_resource_info():
                summary = hub.get_resource_summary()
                return f"""
                ## Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…Ù†Ø§Ø¨Ø¹
                
                - **Ú©Ù„ Ù…Ù†Ø§Ø¨Ø¹:** {summary['total_resources']}
                - **Ù…Ù†Ø§Ø¨Ø¹ Ø±Ø§ÛŒÚ¯Ø§Ù†:** {summary['free_resources']}
                - **Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ AI:** {summary['models_available']}
                - **Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§:** {len(summary['categories'])}
                
                ### Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯:
                {', '.join(summary['categories'].keys()) if summary['categories'] else 'Ù‡ÛŒÚ† Ø¯Ø³ØªÙ‡â€ŒØ§ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯'}
                """

            app.load(fn=get_resource_info, outputs=resource_info)

        # Footer
        gr.Markdown(
            """
        ---
        ### ğŸ“ Ø§Ø·Ù„Ø§Ø¹Ø§Øª
        - **Ù…Ù†Ø§Ø¨Ø¹:** Ø§Ø² ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ JSON Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯Ù‡
        - **Ù…Ø¯Ù„â€ŒÙ‡Ø§:** Hugging Face Transformers
        - **Ø¨Ú©â€ŒØ§Ù†Ø¯:** FastAPI (Ø¯Ø± ØµÙˆØ±Øª Ù…ÙˆØ¬ÙˆØ¯ Ø¨ÙˆØ¯Ù†)
        - **ÙØ±Ø§Ù†Øªâ€ŒØ§Ù†Ø¯:** Gradio
        - **Ù…Ø­ÛŒØ·:** Hugging Face Spaces (Docker)
        """
        )

    return app


# =============================================================================
# Main Entry Point
# =============================================================================

if __name__ == "__main__":
    logger.info("ğŸš€ Starting Crypto Intelligence Hub...")
    logger.info(f"ğŸ“ Workspace: {WORKSPACE_ROOT}")
    logger.info(f"ğŸ³ Docker detected: {IS_DOCKER}")
    logger.info(f"ğŸŒ Use FastAPI+HTML: {USE_FASTAPI_HTML}")
    logger.info(f"ğŸ¨ Use Gradio: {USE_GRADIO}")
    logger.info(f"ğŸ“Š Resources loaded: {len(hub.resources)}")
    logger.info(f"ğŸ¤– Models available: {len(hub.get_available_models())}")
    logger.info(f"ğŸ”Œ FastAPI available: {FASTAPI_AVAILABLE}")

    # Choose mode based on environment variables
    if USE_FASTAPI_HTML and FASTAPI_AVAILABLE:
        # Run FastAPI with HTML interface
        logger.info("ğŸŒ Starting FastAPI server with HTML interface...")
        import uvicorn

        port = int(os.getenv("PORT", "7860"))
        uvicorn.run(fastapi_app, host="0.0.0.0", port=port, log_level="info")
    elif USE_GRADIO:
        # Run Gradio interface (default)
        logger.info("ğŸ¨ Starting Gradio interface...")
        app = create_gradio_interface()
        app.launch(
            server_name="0.0.0.0",
            server_port=int(os.getenv("GRADIO_SERVER_PORT", "7860")),
            share=False,
            show_error=True,
        )
    elif FASTAPI_AVAILABLE:
        # Fallback to FastAPI if Gradio is disabled but FastAPI is available
        logger.info("ğŸŒ Starting FastAPI server (fallback)...")
        import uvicorn

        port = int(os.getenv("PORT", "7860"))
        uvicorn.run(fastapi_app, host="0.0.0.0", port=port, log_level="info")
    else:
        # No UI mode available
        logger.error("âŒ No UI mode available (FastAPI unavailable and Gradio disabled). Exiting.")
        raise SystemExit(1)
