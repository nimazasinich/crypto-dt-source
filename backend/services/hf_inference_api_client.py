#!/usr/bin/env python3
"""
Hugging Face Inference API Client
Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² API Ø¨Ù‡ Ø¬Ø§ÛŒ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø³ØªÙ‚ÛŒÙ… Ù…Ø¯Ù„â€ŒÙ‡Ø§
"""

import aiohttp
import os
from typing import Dict, List, Optional, Any
import asyncio
import logging
from collections import Counter

logger = logging.getLogger(__name__)


class HFInferenceAPIClient:
    """
    Ú©Ù„Ø§ÛŒÙ†Øª Ø¨Ø±Ø§ÛŒ Hugging Face Inference API
    
    Ù…Ø²Ø§ÛŒØ§:
    - Ù†ÛŒØ§Ø²ÛŒ Ø¨Ù‡ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„ Ø¯Ø± RAM Ù†ÛŒØ³Øª
    - Ø¯Ø³ØªØ±Ø³ÛŒ Ø¨Ù‡ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø¨Ø²Ø±Ú¯ØªØ±
    - Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø³Ø±ÛŒØ¹ØªØ± (GPU Ø¯Ø± Ø³Ø±ÙˆØ±Ù‡Ø§ÛŒ HF)
    - 30,000 Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø±Ø§ÛŒÚ¯Ø§Ù† Ø¯Ø± Ù…Ø§Ù‡
    """
    
    def __init__(self, api_token: Optional[str] = None):
        self.api_token = api_token or os.getenv("HF_TOKEN") or os.getenv("HUGGINGFACE_TOKEN")
        self.base_url = "https://api-inference.huggingface.co/models"
        self.session = None
        
        # Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ ØªØ£ÛŒÛŒØ¯ Ø´Ø¯Ù‡ Ú©Ù‡ Ø¯Ø± HF API Ú©Ø§Ø± Ù…ÛŒâ€ŒÚ©Ù†Ù†Ø¯
        self.verified_models = {
            "crypto_sentiment": "kk08/CryptoBERT",
            "social_sentiment": "ElKulako/cryptobert",
            "financial_sentiment": "ProsusAI/finbert",
            "twitter_sentiment": "cardiffnlp/twitter-roberta-base-sentiment-latest",
            "fintwit_sentiment": "StephanAkkerman/FinTwitBERT-sentiment",
            "crypto_gen": "OpenC/crypto-gpt-o3-mini",
            "crypto_trader": "agarkovv/CryptoTrader-LM",
        }
        
        # Cache Ø¨Ø±Ø§ÛŒ Ù†ØªØ§ÛŒØ¬ (Ø¨Ø±Ø§ÛŒ Ú©Ø§Ù‡Ø´ ØªØ¹Ø¯Ø§Ø¯ Ø¯Ø±Ø®ÙˆØ§Ø³Øªâ€ŒÙ‡Ø§)
        self._cache = {}
        self._cache_ttl = 300  # 5 Ø¯Ù‚ÛŒÙ‚Ù‡
    
    async def __aenter__(self):
        self.session = aiohttp.ClientSession()
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        if self.session:
            await self.session.close()
    
    def _get_cache_key(self, text: str, model_key: str) -> str:
        """Ø§ÛŒØ¬Ø§Ø¯ Ú©Ù„ÛŒØ¯ cache"""
        return f"{model_key}:{text[:100]}"
    
    def _check_cache(self, cache_key: str) -> Optional[Dict[str, Any]]:
        """Ø¨Ø±Ø±Ø³ÛŒ cache"""
        if cache_key in self._cache:
            cached_result, timestamp = self._cache[cache_key]
            if asyncio.get_event_loop().time() - timestamp < self._cache_ttl:
                return cached_result
            else:
                del self._cache[cache_key]
        return None
    
    def _set_cache(self, cache_key: str, result: Dict[str, Any]):
        """Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± cache"""
        self._cache[cache_key] = (result, asyncio.get_event_loop().time())
    
    async def analyze_sentiment(
        self, 
        text: str, 
        model_key: str = "crypto_sentiment",
        use_cache: bool = True
    ) -> Dict[str, Any]:
        """
        ØªØ­Ù„ÛŒÙ„ sentiment Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² HF Inference API
        
        Args:
            text: Ù…ØªÙ† Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„
            model_key: Ú©Ù„ÛŒØ¯ Ù…Ø¯Ù„ (crypto_sentiment, social_sentiment, ...)
            use_cache: Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² cache
        
        Returns:
            Dict Ø´Ø§Ù…Ù„ label, confidence, Ùˆ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¯ÛŒÚ¯Ø±
        """
        # Ø¨Ø±Ø±Ø³ÛŒ cache
        if use_cache:
            cache_key = self._get_cache_key(text, model_key)
            cached = self._check_cache(cache_key)
            if cached:
                cached["from_cache"] = True
                return cached
        
        model_id = self.verified_models.get(model_key)
        if not model_id:
            return {
                "status": "error",
                "error": f"Unknown model key: {model_key}. Available: {list(self.verified_models.keys())}"
            }
        
        url = f"{self.base_url}/{model_id}"
        headers = {}
        
        if self.api_token:
            headers["Authorization"] = f"Bearer {self.api_token}"
        
        payload = {"inputs": text[:512]}  # Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Ø·ÙˆÙ„ Ù…ØªÙ†
        
        try:
            if not self.session:
                self.session = aiohttp.ClientSession()
            
            async with self.session.post(
                url, 
                json=payload, 
                headers=headers,
                timeout=aiohttp.ClientTimeout(total=30)
            ) as response:
                
                if response.status == 503:
                    # Ù…Ø¯Ù„ Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø§Ø³Øª
                    return {
                        "status": "loading",
                        "message": "Model is loading, please retry in 20 seconds",
                        "model": model_id
                    }
                
                if response.status == 429:
                    # Ù…Ø­Ø¯ÙˆØ¯ÛŒØª rate limit
                    return {
                        "status": "rate_limited",
                        "error": "Rate limit exceeded. Please try again later.",
                        "model": model_id
                    }
                
                if response.status == 401:
                    return {
                        "status": "error",
                        "error": "Authentication required. Please set HF_TOKEN environment variable.",
                        "model": model_id
                    }
                
                if response.status == 200:
                    data = await response.json()
                    
                    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù†ØªÛŒØ¬Ù‡
                    if isinstance(data, list) and len(data) > 0:
                        if isinstance(data[0], list):
                            # Ø¨Ø±Ø®ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ù„ÛŒØ³ØªÛŒ Ø§Ø² Ù„ÛŒØ³Øªâ€ŒÙ‡Ø§ Ø¨Ø±Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ø§Ù†Ù†Ø¯
                            result = data[0][0] if data[0] else {}
                        else:
                            result = data[0]
                        
                        # Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯Ø³Ø§Ø²ÛŒ Ø®Ø±ÙˆØ¬ÛŒ
                        label = result.get("label", "NEUTRAL").upper()
                        score = result.get("score", 0.5)
                        
                        # ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ ÙØ±Ù…Øª Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯
                        mapped = self._map_label(label)
                        
                        response_data = {
                            "status": "success",
                            "label": mapped,
                            "confidence": score,
                            "score": score,
                            "raw_label": label,
                            "model": model_id,
                            "model_key": model_key,
                            "engine": "hf_inference_api",
                            "available": True,
                            "from_cache": False
                        }
                        
                        # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± cache
                        if use_cache:
                            cache_key = self._get_cache_key(text, model_key)
                            self._set_cache(cache_key, response_data)
                        
                        return response_data
                
                error_text = await response.text()
                logger.warning(f"HF API error: HTTP {response.status}: {error_text[:200]}")
                
                return {
                    "status": "error",
                    "error": f"HTTP {response.status}: {error_text[:200]}",
                    "model": model_id
                }
                
        except asyncio.TimeoutError:
            logger.error(f"HF API timeout for model {model_id}")
            return {
                "status": "error",
                "error": "Request timeout after 30 seconds",
                "model": model_id
            }
        except Exception as e:
            logger.error(f"HF API exception for model {model_id}: {e}")
            return {
                "status": "error",
                "error": str(e)[:200],
                "model": model_id
            }
    
    def _map_label(self, label: str) -> str:
        """ØªØ¨Ø¯ÛŒÙ„ Ø¨Ø±Ú†Ø³Ø¨â€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù Ø¨Ù‡ ÙØ±Ù…Øª Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯"""
        label_upper = label.upper()
        
        # Positive/Bullish mapping
        if any(x in label_upper for x in ["POSITIVE", "BULLISH", "LABEL_2", "BUY"]):
            return "bullish"
        
        # Negative/Bearish mapping
        elif any(x in label_upper for x in ["NEGATIVE", "BEARISH", "LABEL_0", "SELL"]):
            return "bearish"
        
        # Neutral/Hold mapping
        else:
            return "neutral"
    
    async def ensemble_sentiment(
        self, 
        text: str, 
        models: Optional[List[str]] = None,
        min_models: int = 2
    ) -> Dict[str, Any]:
        """
        Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ú†Ù†Ø¯ÛŒÙ† Ù…Ø¯Ù„ Ø¨Ù‡ ØµÙˆØ±Øª Ù‡Ù…Ø²Ù…Ø§Ù† (ensemble)
        
        Args:
            text: Ù…ØªÙ† Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„
            models: Ù„ÛŒØ³Øª Ú©Ù„ÛŒØ¯Ù‡Ø§ÛŒ Ù…Ø¯Ù„ (None = Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ´â€ŒÙØ±Ø¶)
            min_models: Ø­Ø¯Ø§Ù‚Ù„ ØªØ¹Ø¯Ø§Ø¯ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù…ÙˆÙÙ‚ Ø¨Ø±Ø§ÛŒ Ù†ØªÛŒØ¬Ù‡ Ù…Ø¹ØªØ¨Ø±
        
        Returns:
            Dict Ø´Ø§Ù…Ù„ Ù†ØªÛŒØ¬Ù‡ ensemble
        """
        if models is None:
            # Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ´â€ŒÙØ±Ø¶ Ø¨Ø±Ø§ÛŒ ensemble
            models = ["crypto_sentiment", "social_sentiment", "financial_sentiment"]
        
        # ÙØ±Ø§Ø®ÙˆØ§Ù†ÛŒ Ù…ÙˆØ§Ø²ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§
        tasks = [self.analyze_sentiment(text, model) for model in models]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ù†ØªØ§ÛŒØ¬ Ù…ÙˆÙÙ‚
        successful_results = []
        failed_models = []
        loading_models = []
        
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                failed_models.append({
                    "model": models[i],
                    "error": str(result)[:100]
                })
                continue
            
            if isinstance(result, dict):
                if result.get("status") == "success":
                    successful_results.append(result)
                elif result.get("status") == "loading":
                    loading_models.append(result.get("model"))
                else:
                    failed_models.append({
                        "model": models[i],
                        "error": result.get("error", "Unknown error")[:100]
                    })
        
        # Ø§Ú¯Ø± Ù‡Ù…Ù‡ Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù‡Ø³ØªÙ†Ø¯
        if loading_models and not successful_results:
            return {
                "status": "loading",
                "message": f"{len(loading_models)} model(s) are loading",
                "loading_models": loading_models
            }
        
        # Ø§Ú¯Ø± ØªØ¹Ø¯Ø§Ø¯ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù…ÙˆÙÙ‚ Ú©Ù…ØªØ± Ø§Ø² Ø­Ø¯Ø§Ù‚Ù„ Ø¨Ø§Ø´Ø¯
        if len(successful_results) < min_models:
            return {
                "status": "insufficient_models",
                "error": f"Only {len(successful_results)} models succeeded (min: {min_models})",
                "successful": len(successful_results),
                "failed": len(failed_models),
                "failed_models": failed_models[:3],  # Ù†Ù…Ø§ÛŒØ´ 3 Ø®Ø·Ø§ÛŒ Ø§ÙˆÙ„
                "fallback": True
            }
        
        # Ø±Ø§ÛŒâ€ŒÚ¯ÛŒØ±ÛŒ Ø¨ÛŒÙ† Ù†ØªØ§ÛŒØ¬
        labels = [r["label"] for r in successful_results]
        confidences = [r["confidence"] for r in successful_results]
        
        # Ø´Ù…Ø§Ø±Ø´ Ø¢Ø±Ø§
        label_counts = Counter(labels)
        final_label = label_counts.most_common(1)[0][0]
        
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ø¹ØªÙ…Ø§Ø¯ ÙˆØ²Ù†ÛŒ
        # Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒÛŒ Ú©Ù‡ Ø¨Ø§ Ø§Ú©Ø«Ø±ÛŒØª Ù…ÙˆØ§ÙÙ‚ Ù‡Ø³ØªÙ†Ø¯ØŒ ÙˆØ²Ù† Ø¨ÛŒØ´ØªØ±ÛŒ Ø¯Ø§Ø±Ù†Ø¯
        weighted_confidence = sum(
            r["confidence"] for r in successful_results 
            if r["label"] == final_label
        ) / len([r for r in successful_results if r["label"] == final_label])
        
        # Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ú©Ù„
        avg_confidence = sum(confidences) / len(confidences)
        
        # Ø¢Ù…Ø§Ø±Ù‡â€ŒÙ‡Ø§ÛŒ ØªÙØµÛŒÙ„ÛŒ
        scores_breakdown = {
            "bullish": 0.0,
            "bearish": 0.0,
            "neutral": 0.0
        }
        
        for result in successful_results:
            label = result["label"]
            confidence = result["confidence"]
            scores_breakdown[label] += confidence
        
        # Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ
        total_score = sum(scores_breakdown.values())
        if total_score > 0:
            scores_breakdown = {
                k: v / total_score 
                for k, v in scores_breakdown.items()
            }
        
        return {
            "status": "success",
            "label": final_label,
            "confidence": weighted_confidence,
            "avg_confidence": avg_confidence,
            "score": weighted_confidence,
            "scores": scores_breakdown,
            "model_count": len(successful_results),
            "votes": dict(label_counts),
            "consensus": label_counts[final_label] / len(successful_results),
            "models_used": [r["model"] for r in successful_results],
            "engine": "hf_inference_api_ensemble",
            "available": True,
            "failed_count": len(failed_models),
            "failed_models": failed_models[:3] if failed_models else []
        }
    
    async def analyze_with_fallback(
        self, 
        text: str, 
        primary_model: str = "crypto_sentiment",
        fallback_models: Optional[List[str]] = None
    ) -> Dict[str, Any]:
        """
        ØªØ­Ù„ÛŒÙ„ Ø¨Ø§ fallback Ø®ÙˆØ¯Ú©Ø§Ø±
        
        Ø§Ú¯Ø± Ù…Ø¯Ù„ Ø§ØµÙ„ÛŒ Ù…ÙˆÙÙ‚ Ù†Ø´Ø¯ØŒ Ø§Ø² Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ fallback Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯
        """
        if fallback_models is None:
            fallback_models = ["social_sentiment", "financial_sentiment", "twitter_sentiment"]
        
        # ØªÙ„Ø§Ø´ Ø¨Ø§ Ù…Ø¯Ù„ Ø§ØµÙ„ÛŒ
        result = await self.analyze_sentiment(text, primary_model)
        
        if result.get("status") == "success":
            result["used_fallback"] = False
            return result
        
        # ØªÙ„Ø§Ø´ Ø¨Ø§ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ fallback
        for fallback_model in fallback_models:
            result = await self.analyze_sentiment(text, fallback_model)
            
            if result.get("status") == "success":
                result["used_fallback"] = True
                result["fallback_model"] = fallback_model
                result["primary_model_failed"] = primary_model
                return result
        
        # Ù‡Ù…Ù‡ Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ù†Ø§Ù…ÙˆÙÙ‚ Ø¨ÙˆØ¯Ù†Ø¯
        return {
            "status": "all_failed",
            "error": "All models failed",
            "primary_model": primary_model,
            "fallback_models": fallback_models
        }
    
    def get_available_models(self) -> Dict[str, Any]:
        """
        Ø¯Ø±ÛŒØ§ÙØª Ù„ÛŒØ³Øª Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯
        """
        return {
            "total": len(self.verified_models),
            "models": [
                {
                    "key": key,
                    "model_id": model_id,
                    "provider": "HuggingFace",
                    "type": "sentiment" if "sentiment" in key else ("generation" if "gen" in key else "trading")
                }
                for key, model_id in self.verified_models.items()
            ]
        }
    
    def get_cache_stats(self) -> Dict[str, Any]:
        """
        Ø¢Ù…Ø§Ø± cache
        """
        return {
            "cache_size": len(self._cache),
            "cache_ttl": self._cache_ttl
        }


# ===== ØªÙˆØ§Ø¨Ø¹ Ú©Ù…Ú©ÛŒ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø¢Ø³Ø§Ù† =====

async def analyze_crypto_sentiment_via_api(
    text: str, 
    use_ensemble: bool = True
) -> Dict[str, Any]:
    """
    ØªØ­Ù„ÛŒÙ„ sentiment Ú©Ø±ÛŒÙ¾ØªÙˆ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² HF Inference API
    
    Args:
        text: Ù…ØªÙ† Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„
        use_ensemble: Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ensemble (Ú†Ù†Ø¯ Ù…Ø¯Ù„)
    
    Returns:
        Dict Ø´Ø§Ù…Ù„ Ù†ØªÛŒØ¬Ù‡ ØªØ­Ù„ÛŒÙ„
    """
    async with HFInferenceAPIClient() as client:
        if use_ensemble:
            return await client.ensemble_sentiment(text)
        else:
            return await client.analyze_sentiment(text, "crypto_sentiment")


async def quick_sentiment(text: str) -> str:
    """
    ØªØ­Ù„ÛŒÙ„ Ø³Ø±ÛŒØ¹ sentiment - ÙÙ‚Ø· Ø¨Ø±Ú†Ø³Ø¨ Ø±Ø§ Ø¨Ø±Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ø§Ù†Ø¯
    
    Args:
        text: Ù…ØªÙ† Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„
    
    Returns:
        str: "bullish", "bearish", ÛŒØ§ "neutral"
    """
    result = await analyze_crypto_sentiment_via_api(text, use_ensemble=False)
    return result.get("label", "neutral")


# ===== Ù…Ø«Ø§Ù„ Ø§Ø³ØªÙØ§Ø¯Ù‡ =====
if __name__ == "__main__":
    async def test_client():
        """ØªØ³Øª Ú©Ù„Ø§ÛŒÙ†Øª"""
        print("ğŸ§ª Testing HF Inference API Client...")
        
        test_texts = [
            "Bitcoin is showing strong bullish momentum!",
            "Major exchange hacked, prices crashing",
            "Market consolidating, waiting for direction"
        ]
        
        async with HFInferenceAPIClient() as client:
            # ØªØ³Øª ØªÚ© Ù…Ø¯Ù„
            print("\n1ï¸âƒ£ Single Model Test:")
            for text in test_texts:
                result = await client.analyze_sentiment(text, "crypto_sentiment")
                print(f"   Text: {text[:50]}...")
                print(f"   Result: {result.get('label')} ({result.get('confidence', 0):.2%})")
            
            # ØªØ³Øª ensemble
            print("\n2ï¸âƒ£ Ensemble Test:")
            text = "Bitcoin breaking new all-time highs!"
            result = await client.ensemble_sentiment(text)
            print(f"   Text: {text}")
            print(f"   Result: {result.get('label')} ({result.get('confidence', 0):.2%})")
            print(f"   Votes: {result.get('votes')}")
            print(f"   Models: {result.get('model_count')}")
            
            # ØªØ³Øª fallback
            print("\n3ï¸âƒ£ Fallback Test:")
            result = await client.analyze_with_fallback(text)
            print(f"   Used fallback: {result.get('used_fallback', False)}")
            print(f"   Result: {result.get('label')} ({result.get('confidence', 0):.2%})")
            
            # Ù„ÛŒØ³Øª Ù…Ø¯Ù„â€ŒÙ‡Ø§
            print("\n4ï¸âƒ£ Available Models:")
            models = client.get_available_models()
            for model in models["models"][:5]:
                print(f"   - {model['key']}: {model['model_id']}")
        
        print("\nâœ… Testing complete!")
    
    import asyncio
    asyncio.run(test_client())
