#!/usr/bin/env python3
"""
Hugging Face Dataset Loader Service
Ø¯Ø³ØªØ±Ø³ÛŒ Ø¨Ù‡ Datasetâ€ŒÙ‡Ø§ÛŒ Ø±Ø§ÛŒÚ¯Ø§Ù† HuggingFace
"""

import pandas as pd
from typing import Dict, List, Optional, Any, Union
import logging
import asyncio
from datetime import datetime, timedelta

logger = logging.getLogger(__name__)

# Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¬ÙˆØ¯ Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡ datasets
try:
    from datasets import load_dataset
    DATASETS_AVAILABLE = True
except ImportError:
    DATASETS_AVAILABLE = False
    logger.warning("datasets library not available. Install with: pip install datasets")


class HFDatasetService:
    """
    Ø³Ø±ÙˆÛŒØ³ Ø¨Ø±Ø§ÛŒ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ùˆ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Datasetâ€ŒÙ‡Ø§ÛŒ Ø±Ø§ÛŒÚ¯Ø§Ù† HF
    
    Ù…Ø²Ø§ÛŒØ§:
    - Ø¯Ø³ØªØ±Ø³ÛŒ Ø±Ø§ÛŒÚ¯Ø§Ù† Ø¨Ù‡ 100,000+ dataset
    - Ø¯Ø§Ø¯Ù‡ ØªØ§Ø±ÛŒØ®ÛŒ Ú©Ø±ÛŒÙ¾ØªÙˆ
    - Ø¯Ø§Ø¯Ù‡ Ø§Ø®Ø¨Ø§Ø± Ùˆ sentiment
    - Ø¨Ø¯ÙˆÙ† Ù†ÛŒØ§Ø² Ø¨Ù‡ API key (Ø¨Ø±Ø§ÛŒ datasetâ€ŒÙ‡Ø§ÛŒ public)
    """
    
    # Datasetâ€ŒÙ‡Ø§ÛŒ Ù…Ø¹ØªØ¨Ø± Ú©Ø±ÛŒÙ¾ØªÙˆ Ú©Ù‡ ØªØ£ÛŒÛŒØ¯ Ø´Ø¯Ù‡â€ŒØ§Ù†Ø¯
    CRYPTO_DATASETS = {
        "linxy/CryptoCoin": {
            "description": "182 ÙØ§ÛŒÙ„ CSV Ø¨Ø§ OHLCV Ø¨Ø±Ø§ÛŒ 26 Ú©Ø±ÛŒÙ¾ØªÙˆ",
            "symbols": ["BTC", "ETH", "BNB", "SOL", "ADA", "XRP", "DOT", "DOGE", 
                       "AVAX", "MATIC", "LINK", "UNI", "ATOM", "LTC", "XMR"],
            "timeframes": ["1m", "5m", "15m", "30m", "1h", "4h", "1d"],
            "columns": ["timestamp", "open", "high", "low", "close", "volume"],
            "date_range": "2017-present"
        },
        "WinkingFace/CryptoLM-Bitcoin-BTC-USDT": {
            "description": "Ø¯Ø§Ø¯Ù‡ ØªØ§Ø±ÛŒØ®ÛŒ Bitcoin Ø¨Ø§ indicators",
            "symbols": ["BTC"],
            "timeframes": ["1h"],
            "columns": ["timestamp", "open", "high", "low", "close", "volume", "rsi", "macd"],
            "date_range": "2019-2023"
        },
        "sebdg/crypto_data": {
            "description": "OHLCV + indicators Ø¨Ø±Ø§ÛŒ 10 Ú©Ø±ÛŒÙ¾ØªÙˆ",
            "symbols": ["BTC", "ETH", "BNB", "ADA", "DOT", "LINK", "UNI", "AVAX", "MATIC", "SOL"],
            "indicators": ["RSI", "MACD", "Bollinger Bands", "EMA", "SMA"],
            "timeframes": ["1h", "4h", "1d"],
            "date_range": "2020-present"
        }
    }
    
    NEWS_DATASETS = {
        "Kwaai/crypto-news": {
            "description": "Ø§Ø®Ø¨Ø§Ø± Ú©Ø±ÛŒÙ¾ØªÙˆ Ø¨Ø§ sentiment labels",
            "size": "10,000+ news articles",
            "languages": ["en"],
            "date_range": "2020-2023"
        },
        "jacopoteneggi/crypto-news": {
            "description": "Ø§Ø®Ø¨Ø§Ø± Ø±ÙˆØ²Ø§Ù†Ù‡ Ú©Ø±ÛŒÙ¾ØªÙˆ",
            "size": "50,000+ articles",
            "sources": ["CoinDesk", "CoinTelegraph", "Bitcoin Magazine"],
            "date_range": "2018-2023"
        }
    }
    
    def __init__(self):
        self.cache = {}
        self.cache_ttl = 3600  # 1 Ø³Ø§Ø¹Øª
    
    def is_available(self) -> bool:
        """Ø¨Ø±Ø±Ø³ÛŒ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ø¨ÙˆØ¯Ù† Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡ datasets"""
        return DATASETS_AVAILABLE
    
    async def load_crypto_ohlcv(
        self, 
        symbol: str = "BTC", 
        timeframe: str = "1h",
        limit: int = 1000,
        dataset_name: str = "linxy/CryptoCoin"
    ) -> pd.DataFrame:
        """
        Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ OHLCV Ø§Ø² Dataset
        
        Args:
            symbol: Ù†Ù…Ø§Ø¯ Ú©Ø±ÛŒÙ¾ØªÙˆ (BTC, ETH, ...)
            timeframe: Ø¨Ø§Ø²Ù‡ Ø²Ù…Ø§Ù†ÛŒ (1m, 5m, 1h, 1d, ...)
            limit: ØªØ¹Ø¯Ø§Ø¯ Ø±Ú©ÙˆØ±Ø¯
            dataset_name: Ù†Ø§Ù… dataset
        
        Returns:
            DataFrame Ø´Ø§Ù…Ù„ OHLCV
        """
        if not DATASETS_AVAILABLE:
            logger.error("datasets library not available")
            return pd.DataFrame()
        
        try:
            # Ú©Ù„ÛŒØ¯ cache
            cache_key = f"{dataset_name}:{symbol}:{timeframe}:{limit}"
            
            # Ø¨Ø±Ø±Ø³ÛŒ cache
            if cache_key in self.cache:
                cached_data, cached_time = self.cache[cache_key]
                if (datetime.now() - cached_time).total_seconds() < self.cache_ttl:
                    logger.info(f"Returning cached data for {cache_key}")
                    return cached_data
            
            logger.info(f"Loading dataset {dataset_name} for {symbol}...")
            
            # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Dataset
            # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² streaming Ø¨Ø±Ø§ÛŒ ØµØ±ÙÙ‡â€ŒØ¬ÙˆÛŒÛŒ Ø¯Ø± RAM
            dataset = load_dataset(
                dataset_name,
                split="train",
                streaming=True
            )
            
            # ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ DataFrame (Ù…Ø­Ø¯ÙˆØ¯ Ø¨Ù‡ limit Ø±Ú©ÙˆØ±Ø¯)
            records = []
            count = 0
            
            for record in dataset:
                # ÙÛŒÙ„ØªØ± Ø¨Ø± Ø§Ø³Ø§Ø³ symbol (Ø§Ú¯Ø± ÙÛŒÙ„Ø¯ symbol Ù…ÙˆØ¬ÙˆØ¯ Ø¨Ø§Ø´Ø¯)
                if "symbol" in record:
                    if record["symbol"].upper() != symbol.upper():
                        continue
                
                records.append(record)
                count += 1
                
                if count >= limit:
                    break
            
            df = pd.DataFrame(records)
            
            # Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯Ø³Ø§Ø²ÛŒ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§
            if not df.empty:
                # ØªØ¨Ø¯ÛŒÙ„ timestamp Ø§Ú¯Ø± Ø±Ø´ØªÙ‡ Ø§Ø³Øª
                if "timestamp" in df.columns:
                    if df["timestamp"].dtype == "object":
                        df["timestamp"] = pd.to_datetime(df["timestamp"])
                
                # Ù…Ø±ØªØ¨â€ŒØ³Ø§Ø²ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ timestamp
                if "timestamp" in df.columns:
                    df = df.sort_values("timestamp", ascending=False)
                
                # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± cache
                self.cache[cache_key] = (df, datetime.now())
            
            logger.info(f"Loaded {len(df)} records for {symbol}")
            return df
            
        except Exception as e:
            logger.error(f"Error loading dataset: {e}")
            return pd.DataFrame()
    
    async def load_crypto_news(
        self,
        limit: int = 100,
        dataset_name: str = "Kwaai/crypto-news"
    ) -> List[Dict[str, Any]]:
        """
        Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø§Ø®Ø¨Ø§Ø± Ú©Ø±ÛŒÙ¾ØªÙˆ Ø§Ø² Dataset
        
        Args:
            limit: ØªØ¹Ø¯Ø§Ø¯ Ø®Ø¨Ø±
            dataset_name: Ù†Ø§Ù… dataset
        
        Returns:
            Ù„ÛŒØ³Øª Ø§Ø®Ø¨Ø§Ø±
        """
        if not DATASETS_AVAILABLE:
            logger.error("datasets library not available")
            return []
        
        try:
            logger.info(f"Loading news from {dataset_name}...")
            
            # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Dataset
            dataset = load_dataset(
                dataset_name,
                split="train",
                streaming=True
            )
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø®Ø¨Ø§Ø±
            news_items = []
            count = 0
            
            for record in dataset:
                news_item = {
                    "title": record.get("title", ""),
                    "content": record.get("text", record.get("content", "")),
                    "url": record.get("url", ""),
                    "source": record.get("source", "HuggingFace Dataset"),
                    "published_at": record.get("date", record.get("published_at", "")),
                    "sentiment": record.get("sentiment", "neutral")
                }
                
                news_items.append(news_item)
                count += 1
                
                if count >= limit:
                    break
            
            logger.info(f"Loaded {len(news_items)} news articles")
            return news_items
            
        except Exception as e:
            logger.error(f"Error loading news: {e}")
            return []
    
    async def get_historical_prices(
        self,
        symbol: str,
        days: int = 30,
        timeframe: str = "1h"
    ) -> Dict[str, Any]:
        """
        Ø¯Ø±ÛŒØ§ÙØª Ù‚ÛŒÙ…Øªâ€ŒÙ‡Ø§ÛŒ ØªØ§Ø±ÛŒØ®ÛŒ
        
        Args:
            symbol: Ù†Ù…Ø§Ø¯ Ú©Ø±ÛŒÙ¾ØªÙˆ
            days: ØªØ¹Ø¯Ø§Ø¯ Ø±ÙˆØ² Ú¯Ø°Ø´ØªÙ‡
            timeframe: Ø¨Ø§Ø²Ù‡ Ø²Ù…Ø§Ù†ÛŒ
        
        Returns:
            Dict Ø´Ø§Ù…Ù„ Ø¯Ø§Ø¯Ù‡ Ù‚ÛŒÙ…Øª Ùˆ Ø¢Ù…Ø§Ø±
        """
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ ØªØ¹Ø¯Ø§Ø¯ Ø±Ú©ÙˆØ±Ø¯ Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø²
        records_per_day = {
            "1m": 1440,
            "5m": 288,
            "15m": 96,
            "30m": 48,
            "1h": 24,
            "4h": 6,
            "1d": 1
        }
        
        limit = records_per_day.get(timeframe, 24) * days
        
        # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡
        df = await self.load_crypto_ohlcv(symbol, timeframe, limit)
        
        if df.empty:
            return {
                "status": "error",
                "error": "No data available",
                "symbol": symbol
            }
        
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø¢Ù…Ø§Ø±
        latest_close = float(df.iloc[0]["close"]) if "close" in df.columns else 0
        earliest_close = float(df.iloc[-1]["close"]) if "close" in df.columns else 0
        
        price_change = latest_close - earliest_close
        price_change_pct = (price_change / earliest_close * 100) if earliest_close > 0 else 0
        
        high_price = float(df["high"].max()) if "high" in df.columns else 0
        low_price = float(df["low"].min()) if "low" in df.columns else 0
        avg_volume = float(df["volume"].mean()) if "volume" in df.columns else 0
        
        return {
            "status": "success",
            "symbol": symbol,
            "timeframe": timeframe,
            "days": days,
            "records": len(df),
            "latest_price": latest_close,
            "price_change": price_change,
            "price_change_pct": price_change_pct,
            "high": high_price,
            "low": low_price,
            "avg_volume": avg_volume,
            "data": df.to_dict(orient="records")[:100],  # Ù…Ø­Ø¯ÙˆØ¯ Ø¨Ù‡ 100 Ø±Ú©ÙˆØ±Ø¯ Ø§ÙˆÙ„
            "source": "HuggingFace Dataset",
            "is_free": True
        }
    
    def get_available_datasets(self) -> Dict[str, Any]:
        """
        Ù„ÛŒØ³Øª Datasetâ€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯
        """
        return {
            "crypto_data": {
                "total": len(self.CRYPTO_DATASETS),
                "datasets": self.CRYPTO_DATASETS
            },
            "news_data": {
                "total": len(self.NEWS_DATASETS),
                "datasets": self.NEWS_DATASETS
            },
            "library_available": DATASETS_AVAILABLE,
            "installation": "pip install datasets" if not DATASETS_AVAILABLE else "âœ… Installed"
        }
    
    def get_supported_symbols(self) -> List[str]:
        """
        Ù„ÛŒØ³Øª Ù†Ù…Ø§Ø¯Ù‡Ø§ÛŒ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ø´Ø¯Ù‡
        """
        symbols = set()
        for dataset_info in self.CRYPTO_DATASETS.values():
            symbols.update(dataset_info.get("symbols", []))
        return sorted(list(symbols))
    
    def get_supported_timeframes(self) -> List[str]:
        """
        Ù„ÛŒØ³Øª Ø¨Ø§Ø²Ù‡â€ŒÙ‡Ø§ÛŒ Ø²Ù…Ø§Ù†ÛŒ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ø´Ø¯Ù‡
        """
        timeframes = set()
        for dataset_info in self.CRYPTO_DATASETS.values():
            timeframes.update(dataset_info.get("timeframes", []))
        return sorted(list(timeframes))


# ===== ØªÙˆØ§Ø¨Ø¹ Ú©Ù…Ú©ÛŒ =====

async def quick_price_data(
    symbol: str = "BTC",
    days: int = 7
) -> Dict[str, Any]:
    """
    Ø¯Ø±ÛŒØ§ÙØª Ø³Ø±ÛŒØ¹ Ø¯Ø§Ø¯Ù‡ Ù‚ÛŒÙ…Øª
    
    Args:
        symbol: Ù†Ù…Ø§Ø¯ Ú©Ø±ÛŒÙ¾ØªÙˆ
        days: ØªØ¹Ø¯Ø§Ø¯ Ø±ÙˆØ²
    
    Returns:
        Dict Ø´Ø§Ù…Ù„ Ø¯Ø§Ø¯Ù‡ Ùˆ Ø¢Ù…Ø§Ø±
    """
    service = HFDatasetService()
    return await service.get_historical_prices(symbol, days)


async def quick_crypto_news(limit: int = 10) -> List[Dict[str, Any]]:
    """
    Ø¯Ø±ÛŒØ§ÙØª Ø³Ø±ÛŒØ¹ Ø§Ø®Ø¨Ø§Ø± Ú©Ø±ÛŒÙ¾ØªÙˆ
    
    Args:
        limit: ØªØ¹Ø¯Ø§Ø¯ Ø®Ø¨Ø±
    
    Returns:
        Ù„ÛŒØ³Øª Ø§Ø®Ø¨Ø§Ø±
    """
    service = HFDatasetService()
    return await service.load_crypto_news(limit)


# ===== Ù…Ø«Ø§Ù„ Ø§Ø³ØªÙØ§Ø¯Ù‡ =====
if __name__ == "__main__":
    async def test_service():
        """ØªØ³Øª Ø³Ø±ÙˆÛŒØ³"""
        print("ğŸ§ª Testing HF Dataset Service...")
        
        service = HFDatasetService()
        
        # Ø¨Ø±Ø±Ø³ÛŒ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ø¨ÙˆØ¯Ù†
        print(f"\n1ï¸âƒ£ Library available: {service.is_available()}")
        
        if not service.is_available():
            print("   âš ï¸  Install with: pip install datasets")
            return
        
        # Ù„ÛŒØ³Øª datasetâ€ŒÙ‡Ø§
        print("\n2ï¸âƒ£ Available Datasets:")
        datasets = service.get_available_datasets()
        print(f"   Crypto datasets: {datasets['crypto_data']['total']}")
        print(f"   News datasets: {datasets['news_data']['total']}")
        
        # Ù†Ù…Ø§Ø¯Ù‡Ø§ÛŒ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ø´Ø¯Ù‡
        print("\n3ï¸âƒ£ Supported Symbols:")
        symbols = service.get_supported_symbols()
        print(f"   {', '.join(symbols[:10])}...")
        
        # ØªØ³Øª Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù‚ÛŒÙ…Øª
        print("\n4ï¸âƒ£ Loading BTC price data...")
        try:
            result = await service.get_historical_prices("BTC", days=7, timeframe="1h")
            if result["status"] == "success":
                print(f"   âœ… Loaded {result['records']} records")
                print(f"   Latest price: ${result['latest_price']:,.2f}")
                print(f"   Change: {result['price_change_pct']:+.2f}%")
                print(f"   High: ${result['high']:,.2f}")
                print(f"   Low: ${result['low']:,.2f}")
            else:
                print(f"   âŒ Error: {result.get('error')}")
        except Exception as e:
            print(f"   âŒ Exception: {e}")
        
        # ØªØ³Øª Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø§Ø®Ø¨Ø§Ø±
        print("\n5ï¸âƒ£ Loading crypto news...")
        try:
            news = await service.load_crypto_news(limit=5)
            print(f"   âœ… Loaded {len(news)} news articles")
            for i, article in enumerate(news[:3], 1):
                print(f"   {i}. {article['title'][:60]}...")
        except Exception as e:
            print(f"   âŒ Exception: {e}")
        
        print("\nâœ… Testing complete!")
    
    import asyncio
    asyncio.run(test_service())
