# ğŸ¤– Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ú©Ø§Ù…Ù„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ùˆ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ AI

## ğŸ“Š ØªØ­Ù„ÛŒÙ„ ÙˆØ¶Ø¹ÛŒØª ÙØ¹Ù„ÛŒ

### âœ… **Ù†Ù‚Ø§Ø· Ù‚ÙˆØª Ù…ÙˆØ¬ÙˆØ¯**

```python
# ÙØ§ÛŒÙ„ ai_models.py Ø´Ù…Ø§ Ø´Ø§Ù…Ù„:
âœ“ Ø³ÛŒØ³ØªÙ… Ù…Ø¯ÛŒØ±ÛŒØª Ù…Ø¯Ù„ Ù¾ÛŒØ´Ø±ÙØªÙ‡ (ModelRegistry)
âœ“ Health tracking Ø¨Ø±Ø§ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§
âœ“ Self-healing Ùˆ retry mechanism
âœ“ Fallback Ø¨Ù‡ ØªØ­Ù„ÛŒÙ„ Ù„ØºÙˆÛŒ
âœ“ 11 Ù…Ø¯Ù„ Ù…Ø®ØªÙ„Ù Ú©Ø±ÛŒÙ¾ØªÙˆ
âœ“ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ø§Ø² sentimentØŒ trading signalsØŒ Ùˆ generation
```

### âŒ **Ù…Ø´Ú©Ù„Ø§Øª Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯Ù‡**

1. **Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù†Ø´Ø¯Ù‡**
   - Ø¨Ø±Ø®ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ù†ÛŒØ§Ø² Ø¨Ù‡ authentication Ø¯Ø§Ø±Ù†Ø¯
   - Ø¨Ø±Ø®ÛŒ repository Ù‡Ø§ Ù¾ÛŒØ¯Ø§ Ù†Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯
   - Ù…Ø­Ø¯ÙˆØ¯ÛŒØª rate limit Ø¯Ø± Hugging Face

2. **Ù…ØµØ±Ù Ù…Ù†Ø§Ø¨Ø¹**
   - Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ø¯Ø± RAM Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯ (Ù‡Ø± Ú©Ø¯Ø§Ù… 300MB-1GB)
   - Ø¯Ø± Hugging Face Space Ù…Ø­Ø¯ÙˆØ¯ÛŒØª RAM ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯

3. **Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ**
   - Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Inference API Ø¨Ù‡ØªØ± Ø§Ø² Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø³ØªÙ‚ÛŒÙ…
   - Ù†ÛŒØ§Ø² Ø¨Ù‡ caching Ù‡ÙˆØ´Ù…Ù†Ø¯ØªØ±
   - Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø¨Ù‡ÛŒÙ†Ù‡ Ø§Ø² Ù…Ù†Ø§Ø¨Ø¹ Ù…Ø­Ø¯ÙˆØ¯

---

## ğŸš€ **Ø±Ø§Ù‡Ú©Ø§Ø±Ù‡Ø§ÛŒ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ**

### 1ï¸âƒ£ **Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Hugging Face Inference API**

Ø¨Ù‡ Ø¬Ø§ÛŒ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø³ØªÙ‚ÛŒÙ… Ù…Ø¯Ù„â€ŒÙ‡Ø§ØŒ Ø§Ø² API Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯:

```python
# backend/services/hf_inference_api_client.py
import aiohttp
import os
from typing import Dict, List, Optional, Any
import asyncio

class HFInferenceAPIClient:
    """
    Ú©Ù„Ø§ÛŒÙ†Øª Ø¨Ø±Ø§ÛŒ Hugging Face Inference API
    Ù…Ø²Ø§ÛŒØ§:
    - Ù†ÛŒØ§Ø²ÛŒ Ø¨Ù‡ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„ Ø¯Ø± RAM Ù†ÛŒØ³Øª
    - Ø¯Ø³ØªØ±Ø³ÛŒ Ø¨Ù‡ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø¨Ø²Ø±Ú¯ØªØ±
    - Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø³Ø±ÛŒØ¹ØªØ± (GPU Ø¯Ø± Ø³Ø±ÙˆØ±Ù‡Ø§ÛŒ HF)
    - 30,000 Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø±Ø§ÛŒÚ¯Ø§Ù† Ø¯Ø± Ù…Ø§Ù‡
    """
    
    def __init__(self, api_token: Optional[str] = None):
        self.api_token = api_token or os.getenv("HF_TOKEN")
        self.base_url = "https://api-inference.huggingface.co/models"
        self.session = None
        
        # Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ ØªØ£ÛŒÛŒØ¯ Ø´Ø¯Ù‡ Ú©Ù‡ Ø¯Ø± HF API Ú©Ø§Ø± Ù…ÛŒâ€ŒÚ©Ù†Ù†Ø¯
        self.verified_models = {
            "crypto_sentiment": "kk08/CryptoBERT",
            "social_sentiment": "ElKulako/cryptobert",
            "financial_sentiment": "ProsusAI/finbert",
            "twitter_sentiment": "cardiffnlp/twitter-roberta-base-sentiment-latest",
            "crypto_gen": "OpenC/crypto-gpt-o3-mini",
        }
    
    async def __aenter__(self):
        self.session = aiohttp.ClientSession()
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        if self.session:
            await self.session.close()
    
    async def analyze_sentiment(
        self, 
        text: str, 
        model_key: str = "crypto_sentiment"
    ) -> Dict[str, Any]:
        """
        ØªØ­Ù„ÛŒÙ„ sentiment Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² HF Inference API
        """
        model_id = self.verified_models.get(model_key)
        if not model_id:
            return {"error": f"Unknown model key: {model_key}"}
        
        url = f"{self.base_url}/{model_id}"
        headers = {}
        
        if self.api_token:
            headers["Authorization"] = f"Bearer {self.api_token}"
        
        payload = {"inputs": text[:512]}  # Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Ø·ÙˆÙ„ Ù…ØªÙ†
        
        try:
            if not self.session:
                self.session = aiohttp.ClientSession()
            
            async with self.session.post(
                url, 
                json=payload, 
                headers=headers,
                timeout=aiohttp.ClientTimeout(total=30)
            ) as response:
                
                if response.status == 503:
                    # Ù…Ø¯Ù„ Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø§Ø³Øª
                    return {
                        "status": "loading",
                        "message": "Model is loading, please retry in 20 seconds"
                    }
                
                if response.status == 200:
                    data = await response.json()
                    
                    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù†ØªÛŒØ¬Ù‡
                    if isinstance(data, list) and len(data) > 0:
                        if isinstance(data[0], list):
                            result = data[0][0]
                        else:
                            result = data[0]
                        
                        # Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯Ø³Ø§Ø²ÛŒ Ø®Ø±ÙˆØ¬ÛŒ
                        label = result.get("label", "NEUTRAL").upper()
                        score = result.get("score", 0.5)
                        
                        # ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ ÙØ±Ù…Øª Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯
                        mapped = self._map_label(label)
                        
                        return {
                            "status": "success",
                            "label": mapped,
                            "confidence": score,
                            "raw_label": label,
                            "model": model_id,
                            "engine": "hf_inference_api"
                        }
                
                error_text = await response.text()
                return {
                    "status": "error",
                    "error": f"HTTP {response.status}: {error_text[:200]}"
                }
                
        except asyncio.TimeoutError:
            return {
                "status": "error",
                "error": "Request timeout after 30 seconds"
            }
        except Exception as e:
            return {
                "status": "error",
                "error": str(e)[:200]
            }
    
    def _map_label(self, label: str) -> str:
        """ØªØ¨Ø¯ÛŒÙ„ Ø¨Ø±Ú†Ø³Ø¨â€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù Ø¨Ù‡ ÙØ±Ù…Øª Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯"""
        label_upper = label.upper()
        
        if any(x in label_upper for x in ["POSITIVE", "BULLISH", "LABEL_2"]):
            return "bullish"
        elif any(x in label_upper for x in ["NEGATIVE", "BEARISH", "LABEL_0"]):
            return "bearish"
        else:
            return "neutral"
    
    async def ensemble_sentiment(
        self, 
        text: str, 
        models: Optional[List[str]] = None
    ) -> Dict[str, Any]:
        """
        Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ú†Ù†Ø¯ÛŒÙ† Ù…Ø¯Ù„ Ø¨Ù‡ ØµÙˆØ±Øª Ù‡Ù…Ø²Ù…Ø§Ù† (ensemble)
        """
        if models is None:
            models = ["crypto_sentiment", "social_sentiment", "financial_sentiment"]
        
        # ÙØ±Ø§Ø®ÙˆØ§Ù†ÛŒ Ù…ÙˆØ§Ø²ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§
        tasks = [self.analyze_sentiment(text, model) for model in models]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ù†ØªØ§ÛŒØ¬ Ù…ÙˆÙÙ‚
        successful_results = []
        for result in results:
            if isinstance(result, dict) and result.get("status") == "success":
                successful_results.append(result)
        
        if not successful_results:
            return {
                "status": "error",
                "error": "All models failed",
                "fallback": True
            }
        
        # Ø±Ø§ÛŒâ€ŒÚ¯ÛŒØ±ÛŒ Ø¨ÛŒÙ† Ù†ØªØ§ÛŒØ¬
        labels = [r["label"] for r in successful_results]
        confidences = [r["confidence"] for r in successful_results]
        
        # Ø¨Ø±Ú†Ø³Ø¨ Ø¨Ø§ Ø¨ÛŒØ´ØªØ±ÛŒÙ† ÙØ±Ø§ÙˆØ§Ù†ÛŒ
        from collections import Counter
        label_counts = Counter(labels)
        final_label = label_counts.most_common(1)[0][0]
        
        # Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø§Ø¹ØªÙ…Ø§Ø¯
        avg_confidence = sum(confidences) / len(confidences)
        
        return {
            "status": "success",
            "label": final_label,
            "confidence": avg_confidence,
            "model_count": len(successful_results),
            "votes": dict(label_counts),
            "models_used": [r["model"] for r in successful_results],
            "engine": "hf_inference_api_ensemble"
        }


# ===== ØªØ§Ø¨Ø¹ Ú©Ù…Ú©ÛŒ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø¢Ø³Ø§Ù† =====
async def analyze_crypto_sentiment_via_api(text: str) -> Dict[str, Any]:
    """
    ØªØ­Ù„ÛŒÙ„ sentiment Ú©Ø±ÛŒÙ¾ØªÙˆ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² HF Inference API
    """
    async with HFInferenceAPIClient() as client:
        return await client.ensemble_sentiment(text)
```

---

### 2ï¸âƒ£ **Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Datasetâ€ŒÙ‡Ø§ÛŒ Ø±Ø§ÛŒÚ¯Ø§Ù† Hugging Face**

```python
# backend/services/hf_dataset_loader.py
from datasets import load_dataset
import pandas as pd
from typing import Dict, List, Optional

class HFDatasetService:
    """
    Ø³Ø±ÙˆÛŒØ³ Ø¨Ø±Ø§ÛŒ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ùˆ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Datasetâ€ŒÙ‡Ø§ÛŒ Ø±Ø§ÛŒÚ¯Ø§Ù† HF
    """
    
    # Datasetâ€ŒÙ‡Ø§ÛŒ Ù…Ø¹ØªØ¨Ø± Ú©Ø±ÛŒÙ¾ØªÙˆ
    CRYPTO_DATASETS = {
        "linxy/CryptoCoin": {
            "description": "182 ÙØ§ÛŒÙ„ CSV Ø¨Ø§ OHLCV Ø¨Ø±Ø§ÛŒ 26 Ú©Ø±ÛŒÙ¾ØªÙˆ",
            "symbols": ["BTC", "ETH", "BNB", "SOL", "ADA", "XRP", "DOT", "DOGE"],
            "timeframes": ["1m", "5m", "15m", "30m", "1h", "4h", "1d"]
        },
        "WinkingFace/CryptoLM-Bitcoin-BTC-USDT": {
            "description": "Ø¯Ø§Ø¯Ù‡ ØªØ§Ø±ÛŒØ®ÛŒ Bitcoin",
            "timeframes": ["1h"]
        },
        "sebdg/crypto_data": {
            "description": "OHLCV + indicators Ø¨Ø±Ø§ÛŒ 10 Ú©Ø±ÛŒÙ¾ØªÙˆ",
            "indicators": ["RSI", "MACD", "Bollinger Bands"]
        }
    }
    
    async def load_crypto_ohlcv(
        self, 
        symbol: str = "BTC", 
        timeframe: str = "1h",
        limit: int = 1000
    ) -> pd.DataFrame:
        """
        Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ OHLCV Ø§Ø² Dataset
        """
        try:
            # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø§Ø² linxy/CryptoCoin
            dataset_name = f"linxy/CryptoCoin"
            
            # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Dataset
            dataset = load_dataset(
                dataset_name,
                split="train",
                streaming=True  # Ø¨Ø±Ø§ÛŒ ØµØ±ÙÙ‡â€ŒØ¬ÙˆÛŒÛŒ Ø¯Ø± RAM
            )
            
            # ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ DataFrame
            df = pd.DataFrame(dataset.take(limit))
            
            # ÙÛŒÙ„ØªØ± Ø¨Ø± Ø§Ø³Ø§Ø³ symbol
            if "symbol" in df.columns:
                df = df[df["symbol"] == symbol]
            
            return df
            
        except Exception as e:
            print(f"Error loading dataset: {e}")
            return pd.DataFrame()
    
    def get_available_datasets(self) -> Dict[str, Any]:
        """
        Ù„ÛŒØ³Øª Datasetâ€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯
        """
        return {
            "total": len(self.CRYPTO_DATASETS),
            "datasets": self.CRYPTO_DATASETS
        }
```

---

### 3ï¸âƒ£ **Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¨Ø±Ø§ÛŒ Hugging Face Space**

```python
# hf_space_optimized_app.py
"""
Ù†Ø³Ø®Ù‡ Ø¨Ù‡ÛŒÙ†Ù‡ Ø´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙ‚Ø±Ø§Ø± Ø¯Ø± Hugging Face Space
"""

import gradio as gr
import asyncio
from backend.services.hf_inference_api_client import HFInferenceAPIClient

# ===== ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø¨Ù‡ÛŒÙ†Ù‡ Ø¨Ø±Ø§ÛŒ HF Space =====
HF_SPACE_CONFIG = {
    "enable_local_models": False,  # ØºÛŒØ±ÙØ¹Ø§Ù„ Ú©Ø±Ø¯Ù† Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø³ØªÙ‚ÛŒÙ…
    "use_inference_api": True,      # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Inference API
    "cache_results": True,          # Cache Ú©Ø±Ø¯Ù† Ù†ØªØ§ÛŒØ¬
    "max_concurrent": 5,            # Ø­Ø¯Ø§Ú©Ø«Ø± Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ù‡Ù…Ø²Ù…Ø§Ù†
    "timeout": 30                   # Timeout (Ø«Ø§Ù†ÛŒÙ‡)
}

# ===== Ú©Ù„Ø§ÛŒÙ†Øª Ø³Ø±Ø§Ø³Ø±ÛŒ =====
hf_client = None

async def get_hf_client():
    """Ø¯Ø±ÛŒØ§ÙØª Ú©Ù„Ø§ÛŒÙ†Øª HF (Singleton)"""
    global hf_client
    if hf_client is None:
        hf_client = HFInferenceAPIClient()
        await hf_client.__aenter__()
    return hf_client

# ===== ØªÙˆØ§Ø¨Ø¹ UI =====
async def analyze_text(text: str, analysis_type: str):
    """
    ØªØ­Ù„ÛŒÙ„ Ù…ØªÙ† Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² HF Inference API
    """
    if not text:
        return "âš ï¸ Ù„Ø·ÙØ§Ù‹ Ù…ØªÙ†ÛŒ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯"
    
    client = await get_hf_client()
    
    if analysis_type == "Crypto Sentiment":
        result = await client.analyze_sentiment(text, "crypto_sentiment")
    elif analysis_type == "Social Sentiment":
        result = await client.analyze_sentiment(text, "social_sentiment")
    elif analysis_type == "Financial Sentiment":
        result = await client.analyze_sentiment(text, "financial_sentiment")
    elif analysis_type == "Ensemble (All Models)":
        result = await client.ensemble_sentiment(text)
    else:
        return "âŒ Ù†ÙˆØ¹ ØªØ­Ù„ÛŒÙ„ Ù†Ø§Ù…Ø¹ØªØ¨Ø±"
    
    if result.get("status") == "success":
        label = result["label"]
        confidence = result["confidence"]
        emoji = "ğŸ“ˆ" if label == "bullish" else ("ğŸ“‰" if label == "bearish" else "â¡ï¸")
        
        output = f"""
{emoji} **Sentiment**: {label.upper()}
ğŸ¯ **Confidence**: {confidence:.2%}
ğŸ¤– **Engine**: {result.get('engine', 'unknown')}
        """
        
        if result.get("model_count"):
            output += f"\nğŸ“Š **Models Used**: {result['model_count']}"
        
        if result.get("votes"):
            output += f"\nğŸ—³ï¸ **Votes**: {result['votes']}"
        
        return output.strip()
    
    elif result.get("status") == "loading":
        return "â³ Model is loading, please try again in 20 seconds..."
    
    else:
        return f"âŒ Error: {result.get('error', 'Unknown error')}"

# ===== Ø§ÛŒØ¬Ø§Ø¯ Ø±Ø§Ø¨Ø· Gradio =====
def create_optimized_interface():
    """
    Ø§ÛŒØ¬Ø§Ø¯ Ø±Ø§Ø¨Ø· Ø¨Ù‡ÛŒÙ†Ù‡ Ø´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ HF Space
    """
    
    with gr.Blocks(
        title="Crypto AI Analyzer - Optimized for HF Space",
        theme=gr.themes.Soft()
    ) as demo:
        
        gr.Markdown("""
        # ğŸ¤– Crypto AI Analyzer
        ### ØªØ­Ù„ÛŒÙ„ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ù…ØªÙ†â€ŒÙ‡Ø§ÛŒ Ú©Ø±ÛŒÙ¾ØªÙˆ
        
        Ø§ÛŒÙ† Ù†Ø³Ø®Ù‡ Ø¨Ù‡ÛŒÙ†Ù‡ Ø´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Hugging Face Space Ø§Ø³Øª Ùˆ Ø§Ø² **Inference API** Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
        """)
        
        with gr.Tab("ğŸ’¬ Sentiment Analysis"):
            gr.Markdown("### ØªØ­Ù„ÛŒÙ„ Ø§Ø­Ø³Ø§Ø³Ø§Øª Ù…ØªÙ†")
            
            text_input = gr.Textbox(
                label="Ù…ØªÙ† Ø®ÙˆØ¯ Ø±Ø§ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯",
                placeholder="Bitcoin is showing strong bullish momentum...",
                lines=3
            )
            
            analysis_type = gr.Radio(
                choices=[
                    "Crypto Sentiment",
                    "Social Sentiment", 
                    "Financial Sentiment",
                    "Ensemble (All Models)"
                ],
                value="Ensemble (All Models)",
                label="Ù†ÙˆØ¹ ØªØ­Ù„ÛŒÙ„"
            )
            
            analyze_btn = gr.Button("ğŸ” Analyze", variant="primary")
            output = gr.Markdown()
            
            analyze_btn.click(
                fn=analyze_text,
                inputs=[text_input, analysis_type],
                outputs=output
            )
        
        with gr.Tab("ğŸ“Š Available Models"):
            gr.Markdown("""
            ### Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯
            
            | Model | Description | Provider |
            |-------|-------------|----------|
            | kk08/CryptoBERT | Crypto sentiment (binary) | HuggingFace |
            | ElKulako/cryptobert | Social crypto sentiment | HuggingFace |
            | ProsusAI/finbert | Financial sentiment | HuggingFace |
            | cardiffnlp/twitter-roberta | Twitter sentiment | HuggingFace |
            | OpenC/crypto-gpt-o3-mini | Crypto text generation | HuggingFace |
            
            **Ù…Ø²Ø§ÛŒØ§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Inference API:**
            - âœ… Ø¨Ø¯ÙˆÙ† Ù†ÛŒØ§Ø² Ø¨Ù‡ RAM Ø²ÛŒØ§Ø¯
            - âœ… Ø¯Ø³ØªØ±Ø³ÛŒ Ø¨Ù‡ GPU Ø±Ø§ÛŒÚ¯Ø§Ù†
            - âœ… 30,000 Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø±Ø§ÛŒÚ¯Ø§Ù† Ø¯Ø± Ù…Ø§Ù‡
            - âœ… Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø³Ø±ÛŒØ¹â€ŒØªØ±
            """)
        
        with gr.Tab("â„¹ï¸ About"):
            gr.Markdown("""
            ### Ø¯Ø±Ø¨Ø§Ø±Ù‡ Ø§ÛŒÙ† Ù¾Ø±ÙˆÚ˜Ù‡
            
            Ø§ÛŒÙ† Ø§Ø¨Ø²Ø§Ø± Ø§Ø² **Hugging Face Inference API** Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ ØªØ§:
            1. Ù…Ù†Ø§Ø¨Ø¹ RAM Ø±Ø§ Ø­ÙØ¸ Ú©Ù†Ø¯
            2. Ø³Ø±Ø¹Øª Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø±Ø§ Ø§ÙØ²Ø§ÛŒØ´ Ø¯Ù‡Ø¯
            3. Ø¨Ù‡ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø¨Ø²Ø±Ú¯ØªØ± Ø¯Ø³ØªØ±Ø³ÛŒ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯
            4. Ø¯Ø± Hugging Face Space Ø¨Ù‡ Ø®ÙˆØ¨ÛŒ Ú©Ø§Ø± Ú©Ù†Ø¯
            
            **Ù…Ù†Ø§Ø¨Ø¹:**
            - [Hugging Face Models](https://huggingface.co/models)
            - [Inference API Docs](https://huggingface.co/docs/api-inference)
            - [Free Datasets](https://huggingface.co/datasets)
            """)
    
    return demo

# ===== Ø§Ø¬Ø±Ø§ =====
if __name__ == "__main__":
    demo = create_optimized_interface()
    demo.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=False
    )
```

---

### 4ï¸âƒ£ **ÛŒÚ©Ù¾Ø§Ø±Ú†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¨Ø§ Ù¾Ø±ÙˆÚ˜Ù‡ ÙØ¹Ù„ÛŒ**

```python
# backend/services/ai_service_unified.py
"""
Ø³Ø±ÙˆÛŒØ³ ÛŒÚ©Ù¾Ø§Ø±Ú†Ù‡ AI Ú©Ù‡ Ø§Ø² Ù‡Ø± Ø¯Ùˆ Ø±ÙˆØ´ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯
"""

import os
from typing import Dict, Any, Optional
from ai_models import ensemble_crypto_sentiment as local_ensemble
from backend.services.hf_inference_api_client import HFInferenceAPIClient

class UnifiedAIService:
    """
    Ø³Ø±ÙˆÛŒØ³ ÛŒÚ©Ù¾Ø§Ø±Ú†Ù‡ Ú©Ù‡ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù…Ø­ÛŒØ·ØŒ Ø¨Ù‡ØªØ±ÛŒÙ† Ø±ÙˆØ´ Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ù…ÛŒâ€ŒÚ©Ù†Ø¯
    """
    
    def __init__(self):
        self.is_hf_space = bool(os.getenv("SPACE_ID"))
        self.use_api = os.getenv("USE_HF_API", "true").lower() == "true"
        self.hf_client = None
    
    async def analyze_sentiment(self, text: str) -> Dict[str, Any]:
        """
        ØªØ­Ù„ÛŒÙ„ sentiment Ø¨Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ø®ÙˆØ¯Ú©Ø§Ø± Ø±ÙˆØ´ Ø¨Ù‡ÛŒÙ†Ù‡
        """
        # Ø¯Ø± HF Space ÛŒØ§ Ø¨Ø§ USE_HF_API=trueØŒ Ø§Ø² API Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†
        if self.is_hf_space or self.use_api:
            return await self._analyze_via_api(text)
        else:
            # Ø¯Ø± localØŒ Ø§Ø² Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯Ù‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†
            return self._analyze_via_local(text)
    
    async def _analyze_via_api(self, text: str) -> Dict[str, Any]:
        """Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² HF Inference API"""
        if self.hf_client is None:
            self.hf_client = HFInferenceAPIClient()
            await self.hf_client.__aenter__()
        
        return await self.hf_client.ensemble_sentiment(text)
    
    def _analyze_via_local(self, text: str) -> Dict[str, Any]:
        """Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ local"""
        return local_ensemble(text)
    
    def get_service_info(self) -> Dict[str, Any]:
        """Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø³Ø±ÙˆÛŒØ³"""
        return {
            "is_hf_space": self.is_hf_space,
            "using_api": self.use_api,
            "mode": "HF Inference API" if (self.is_hf_space or self.use_api) else "Local Models"
        }
```

---

## ğŸ“¦ **ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø² Ø¨Ø±Ø§ÛŒ HF Space**

### `requirements.txt` (Ø¨Ù‡ÛŒÙ†Ù‡ Ø´Ø¯Ù‡)
```txt
# Core dependencies
fastapi==0.104.1
uvicorn[standard]==0.24.0
gradio==4.8.0
aiohttp==3.9.1
python-dotenv==1.0.0

# HuggingFace (ÙÙ‚Ø· Ø¨Ø±Ø§ÛŒ API Ùˆ Dataset)
huggingface-hub==0.19.4
datasets==2.15.0

# Data processing
pandas==2.1.3
numpy==1.26.2

# Optional: ÙÙ‚Ø· Ø§Ú¯Ø± Ù…ÛŒâ€ŒØ®ÙˆØ§Ù‡ÛŒØ¯ Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ø±Ø§ local Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ú©Ù†ÛŒØ¯
# transformers==4.35.2
# torch==2.1.1
```

### `README.md` (Ø¨Ø±Ø§ÛŒ HF Space)
```markdown
---
title: Crypto AI Analyzer
emoji: ğŸ¤–
colorFrom: blue
colorTo: green
sdk: gradio
sdk_version: 4.8.0
app_file: hf_space_optimized_app.py
pinned: false
license: mit
---

# Crypto AI Analyzer

ØªØ­Ù„ÛŒÙ„ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ù…ØªÙ†â€ŒÙ‡Ø§ÛŒ Ú©Ø±ÛŒÙ¾ØªÙˆ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Hugging Face Inference API.

## Features
- ğŸ¯ Sentiment analysis (Crypto, Social, Financial)
- ğŸ¤– Ensemble learning from multiple models
- ğŸ“Š Free access to 30,000 API calls per month
- âš¡ Fast processing with GPU acceleration

## Models Used
- kk08/CryptoBERT
- ElKulako/cryptobert
- ProsusAI/finbert
- cardiffnlp/twitter-roberta-base-sentiment-latest

## Usage
Simply enter your text and select the analysis type!
```

---

## ğŸ¯ **Ù…Ø²Ø§ÛŒØ§ÛŒ Ø±ÙˆÛŒÚ©Ø±Ø¯ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ**

### Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø±ÙˆØ´â€ŒÙ‡Ø§

| ÙˆÛŒÚ˜Ú¯ÛŒ | Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø³ØªÙ‚ÛŒÙ… | Inference API |
|-------|------------------|---------------|
| **Ù…ØµØ±Ù RAM** | 1-4 GB | < 100 MB |
| **Ø³Ø±Ø¹Øª** | Ø³Ø±ÛŒØ¹ (Ø¨Ø¹Ø¯ Ø§Ø² Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ) | Ø³Ø±ÛŒØ¹ (GPU Ø¯Ø± Ø³Ø±ÙˆØ± HF) |
| **Ù…Ø­Ø¯ÙˆØ¯ÛŒØª** | RAM Ù…Ø­Ø¯ÙˆØ¯ Ø¯Ø± HF Space | 30K req/month Ø±Ø§ÛŒÚ¯Ø§Ù† |
| **Ø¯Ø³ØªØ±Ø³ÛŒ Ø¨Ù‡ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø¨Ø²Ø±Ú¯** | âŒ | âœ… |
| **Ù†ÛŒØ§Ø² Ø¨Ù‡ GPU** | âœ… (Ø¨Ø±Ø§ÛŒ Ø³Ø±Ø¹Øª) | âŒ |
| **Ù‡Ø²ÛŒÙ†Ù‡** | Ø±Ø§ÛŒÚ¯Ø§Ù† Ø§Ù…Ø§ Ù…Ø­Ø¯ÙˆØ¯ | Ø±Ø§ÛŒÚ¯Ø§Ù† ØªØ§ 30K |

---

## ğŸš€ **Ù…Ø±Ø§Ø­Ù„ Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ**

### Ù…Ø±Ø­Ù„Ù‡ 1: Ø§ÛŒØ¬Ø§Ø¯ Ú©Ù„Ø§ÛŒÙ†Øª API
```bash
# Ø§ÛŒØ¬Ø§Ø¯ ÙØ§ÛŒÙ„
touch backend/services/hf_inference_api_client.py

# Ú©Ù¾ÛŒ Ú©Ø±Ø¯Ù† Ú©Ø¯ Ø¨Ø§Ù„Ø§
```

### Ù…Ø±Ø­Ù„Ù‡ 2: ØªØ³Øª Ú©Ù„Ø§ÛŒÙ†Øª
```python
import asyncio
from backend.services.hf_inference_api_client import analyze_crypto_sentiment_via_api

async def test():
    text = "Bitcoin is showing strong bullish momentum!"
    result = await analyze_crypto_sentiment_via_api(text)
    print(result)

asyncio.run(test())
```

### Ù…Ø±Ø­Ù„Ù‡ 3: ÛŒÚ©Ù¾Ø§Ø±Ú†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¨Ø§ Ù¾Ø±ÙˆÚ˜Ù‡
```python
# Ø¯Ø± backend/routers/hf_inference.py
from fastapi import APIRouter
from backend.services.ai_service_unified import UnifiedAIService

router = APIRouter()
ai_service = UnifiedAIService()

@router.post("/api/ai/sentiment")
async def analyze_sentiment(text: str):
    return await ai_service.analyze_sentiment(text)
```

### Ù…Ø±Ø­Ù„Ù‡ 4: Ø§Ø³ØªÙ‚Ø±Ø§Ø± Ø¯Ø± HF Space
```bash
# 1. Ø§ÛŒØ¬Ø§Ø¯ Space Ø¬Ø¯ÛŒØ¯ Ø¯Ø± huggingface.co
# 2. Ø¢Ù¾Ù„ÙˆØ¯ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§:
#    - hf_space_optimized_app.py
#    - requirements.txt  
#    - README.md
# 3. ØªÙ†Ø¸ÛŒÙ… Ù…ØªØºÛŒØ±Ù‡Ø§ÛŒ Ù…Ø­ÛŒØ·ÛŒ
#    HF_TOKEN=your_token
```

---

## ğŸ’° **Ù…Ù†Ø§Ø¨Ø¹ Ø±Ø§ÛŒÚ¯Ø§Ù† Ø§Ø¶Ø§ÙÛŒ**

Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø§ÛŒÙ† Ø±ÙˆÛŒÚ©Ø±Ø¯ØŒ Ø¨Ù‡ Ù…Ù†Ø§Ø¨Ø¹ Ø²ÛŒØ± Ø¯Ø³ØªØ±Ø³ÛŒ Ø®ÙˆØ§Ù‡ÛŒØ¯ Ø¯Ø§Ø´Øª:

### 1. **Inference API** (30,000 req/month)
```python
# Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø±Ø§ÛŒÚ¯Ø§Ù† Ø§Ø² 1000+ Ù…Ø¯Ù„
- Sentiment analysis
- Text generation  
- Question answering
- Translation
- Summarization
```

### 2. **Datasets** (Ù†Ø§Ù…Ø­Ø¯ÙˆØ¯)
```python
# Ø¯Ø³ØªØ±Ø³ÛŒ Ø¨Ù‡ 100,000+ dataset Ø±Ø§ÛŒÚ¯Ø§Ù†
- Historical crypto prices
- News articles
- Social media data
- Training data
```

### 3. **Spaces** (Free tier)
```python
# Ù‡Ø§Ø³Øª Ø±Ø§ÛŒÚ¯Ø§Ù† Ø¨Ø±Ø§ÛŒ Ø§Ù¾Ù„ÛŒÚ©ÛŒØ´Ù†
- 2 vCPU
- 16 GB RAM
- 50 GB Storage
- Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ø§Ø² Gradio/Streamlit/Docker
```

### 4. **Models** (Ù†Ø§Ù…Ø­Ø¯ÙˆØ¯)
```python
# Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ´â€ŒØ¢Ù…ÙˆØ²Ø´ Ø¯Ø§Ø¯Ù‡ Ø´Ø¯Ù‡
- 400,000+ Ù…Ø¯Ù„
- ØªÙ…Ø§Ù… open source
- Ø¨Ø¯ÙˆÙ† Ù†ÛŒØ§Ø² Ø¨Ù‡ training
```

---

## ğŸ“ˆ **Ù†Ù…ÙˆÙ†Ù‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ ÙˆØ§Ù‚Ø¹ÛŒ**

```python
# Ù…Ø«Ø§Ù„ Ú©Ø§Ù…Ù„: Ø³ÛŒØ³ØªÙ… ØªØ­Ù„ÛŒÙ„ Ø®Ø¨Ø± Ø¨Ø§ AI

import asyncio
from backend.services.hf_inference_api_client import HFInferenceAPIClient
from backend.services.hf_dataset_loader import HFDatasetService

async def analyze_crypto_news():
    """
    Ø³ÛŒØ³ØªÙ… Ú©Ø§Ù…Ù„ ØªØ­Ù„ÛŒÙ„ Ø®Ø¨Ø±:
    1. Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡ ØªØ§Ø±ÛŒØ®ÛŒ Ø§Ø² Dataset
    2. ØªØ­Ù„ÛŒÙ„ sentiment Ø®Ø¨Ø±Ù‡Ø§ Ø¨Ø§ AI
    3. ØªØ±Ú©ÛŒØ¨ Ø¨Ø§ Ù‚ÛŒÙ…Øªâ€ŒÙ‡Ø§
    """
    
    # 1. Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡ Ù‚ÛŒÙ…Øª
    dataset_service = HFDatasetService()
    btc_data = await dataset_service.load_crypto_ohlcv("BTC", "1h", 100)
    print(f"âœ… Loaded {len(btc_data)} price records")
    
    # 2. ØªØ­Ù„ÛŒÙ„ sentiment
    async with HFInferenceAPIClient() as client:
        news_items = [
            "Bitcoin breaks all-time high!",
            "Major exchange hacked, millions lost",
            "Institutional adoption growing steadily"
        ]
        
        sentiments = []
        for news in news_items:
            result = await client.analyze_sentiment(news, "crypto_sentiment")
            sentiments.append({
                "news": news,
                "sentiment": result.get("label"),
                "confidence": result.get("confidence")
            })
        
        print(f"âœ… Analyzed {len(sentiments)} news items")
    
    # 3. ØªØ±Ú©ÛŒØ¨ Ùˆ ØªØ­Ù„ÛŒÙ„
    return {
        "price_data": btc_data.to_dict(),
        "sentiment_analysis": sentiments,
        "summary": {
            "bullish_news": sum(1 for s in sentiments if s["sentiment"] == "bullish"),
            "bearish_news": sum(1 for s in sentiments if s["sentiment"] == "bearish"),
            "avg_confidence": sum(s["confidence"] for s in sentiments) / len(sentiments)
        }
    }

# Ø§Ø¬Ø±Ø§
result = asyncio.run(analyze_crypto_news())
print(result["summary"])
```

---

## âœ… **Ø®Ù„Ø§ØµÙ‡ Ùˆ ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§**

### ğŸ¯ **ØªÙˆØµÛŒÙ‡ Ø§ØµÙ„ÛŒ**
Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² **Hugging Face Inference API** Ø¨Ù‡ Ø¬Ø§ÛŒ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø³ØªÙ‚ÛŒÙ… Ù…Ø¯Ù„â€ŒÙ‡Ø§:

1. âœ… **ØµØ±ÙÙ‡â€ŒØ¬ÙˆÛŒÛŒ Ù…Ù†Ø§Ø¨Ø¹**: Ø¨Ø¯ÙˆÙ† Ù†ÛŒØ§Ø² Ø¨Ù‡ RAM Ø²ÛŒØ§Ø¯
2. âœ… **Ø³Ø±Ø¹Øª Ø¨ÛŒØ´ØªØ±**: GPU Ø±Ø§ÛŒÚ¯Ø§Ù† Ø¯Ø± Ø³Ø±ÙˆØ±Ù‡Ø§ÛŒ HF
3. âœ… **Ø¯Ø³ØªØ±Ø³ÛŒ Ø¨ÛŒØ´ØªØ±**: Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø¨Ø²Ø±Ú¯ØªØ±
4. âœ… **Ø±Ø§ÛŒÚ¯Ø§Ù†**: 30,000 Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø¯Ø± Ù…Ø§Ù‡

### ğŸ“¦ **Ù…Ù†Ø§Ø¨Ø¹ Ø±Ø§ÛŒÚ¯Ø§Ù† Ø§Ø¶Ø§ÙÛŒ**
- Inference API: 30K req/month
- Datasets: Ù†Ø§Ù…Ø­Ø¯ÙˆØ¯
- Spaces: Ù‡Ø§Ø³Øª Ø±Ø§ÛŒÚ¯Ø§Ù†
- Models: 400K+ Ù…Ø¯Ù„

### ğŸš€ **Ù…Ø±Ø§Ø­Ù„ Ø¨Ø¹Ø¯ÛŒ**
1. Ø§ÛŒØ¬Ø§Ø¯ `hf_inference_api_client.py`
2. ØªØ³Øª Ø¨Ø§ Ú†Ù†Ø¯ Ù†Ù…ÙˆÙ†Ù‡
3. ÛŒÚ©Ù¾Ø§Ø±Ú†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¨Ø§ Ù¾Ø±ÙˆÚ˜Ù‡ ÙØ¹Ù„ÛŒ
4. Ø§Ø³ØªÙ‚Ø±Ø§Ø± Ø¯Ø± HF Space
5. Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Datasetâ€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ Ø¯Ø§Ø¯Ù‡ ØªØ§Ø±ÛŒØ®ÛŒ

---

**Ø¨Ø§ Ø§ÛŒÙ† Ø±ÙˆÛŒÚ©Ø±Ø¯ØŒ Ø¨Ù‡ ØµÙˆØ±Øª Ú©Ø§Ù…Ù„Ø§Ù‹ Ø±Ø§ÛŒÚ¯Ø§Ù† Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯:**
- âœ… 30,000 ØªØ­Ù„ÛŒÙ„ sentiment Ø¯Ø± Ù…Ø§Ù‡
- âœ… Ø¯Ø³ØªØ±Ø³ÛŒ Ø¨Ù‡ 100,000+ dataset
- âœ… Ù‡Ø§Ø³Øª Ø±Ø§ÛŒÚ¯Ø§Ù† Ø§Ù¾Ù„ÛŒÚ©ÛŒØ´Ù†
- âœ… Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² 400,000+ Ù…Ø¯Ù„ AI
